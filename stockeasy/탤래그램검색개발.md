1. 배경 및 요구사항
텔레그램 채널에 올라오는 주식 정보(짧은 뉴스, 장중 등락율, 장마감 종가, 호재/악재성 이슈 등)를 내 웹 서비스에서 요약해 보고 싶다.
특정 종목 정보만 모아서 보고 싶을 수도 있고, 전체 시장 소식을 요약해 볼 수도 있어야 한다.
문서(PDF 리포트 등) 첨부가 텔레그램에 올라올 수도 있는데, 이것은 이미 다른 RAG 시스템이 처리 중이므로, 여기서는 파일 URL만 가져와서 iFrame(또는 링크)으로 보여주면 된다.
**임베딩(RAG)**을 도입하기로 결정: 메시지를 Pinecone에 임베딩해두고, 검색 시 메타데이터 필터 또는 유사도 검색을 활용한다.
SQL만으로도 간단한 종목/날짜 검색은 가능하지만, 향후 확장성(유사 표현 검색, 자연어 질의 등)을 위해 임베딩 기반을 택했다.
2. 전체 아키텍처 개요
텔레그램 메시지 수집:

Telethon(혹은 Pyrogram) + API ID, Hash를 이용해 특정 채널에 대한 메시지를 실시간 이벤트로 받음.
새 메시지가 오면 DB(PostgreSQL 등)에 저장.
(필드 예시) id, message_id, text, stocks(배열), created_at, file_url(첨부), is_embedded 등.
종목명 추출: 메시지 본문에서 “삼성전자”, “SK하이닉스” 등 키워드를 찾으면 stocks = ["삼성전자","SK하이닉스"]처럼 저장.
여러 종목이 함께 언급될 수 있으므로 배열로 처리.
임베딩 & Pinecone 인덱싱:

5분 또는 10분 배치(Celery beat, cron 등)로 DB에서 “새로 수집된 메시지”를 가져와 OpenAI Embedding(text-embedding-ada-002) 생성 후, Pinecone에 업서트(upsert).
메타데이터로 {"date":"2025-01-31", "stocks":["삼성전자"], "file_url":"..."} 등을 저장.
첨부 PDF는 여기서 임베딩하지 않음(다른 RAG가 처리). 이쪽엔 URL만 기록.
검색 & 요약:

사용자(또는 관리자)가 “오늘 삼성전자 소식 요약” → Pinecone에서 stocks에 “삼성전자” 포함 + “date=오늘”로 필터 → 상위 N개 메시지 가져오기.
결과 메시지들을 한꺼번에 **LLM(GPT)**에 전달 → 요약문 얻기.
첨부파일이 있다면 URL을 iFrame/링크로 표시.
3. 임베딩 주기: 실시간 vs. 배치
실시간(메시지마다):
메시지 올라올 때마다 곧바로 임베딩 → 검색에 즉시 반영.
메시지가 폭주하면 비용과 부하가 큼.
배치(5분, 10분 등):
5분 간격으로 “신규 메시지”만 모아 임베딩.
약간(최대 5분) 늦게 검색결과에 반영되지만, 서버부하와 비용이 절감.
결정:

장중(아침 7시~오후 5시)에는 뉴스가 중요하므로 5분 간격으로 임베딩.
장마감 후(오후 5시 이후)에는 뉴스량이 줄고 긴급성도 떨어지므로 30분 간격으로 임베딩.
4. Celery를 이용한 시간대별 스케줄 (아침 7시~오후 5시 vs. 그 외)
Celery + Redis를 이미 사용 중이므로, Celery Beat 설정을 통해 시간대별 다른 간격을 적용한다.

Celery Beat 설정 예시:

python
복사
편집
from celery.schedules import crontab

app.conf.beat_schedule = {
    'embedding_morning_day': {
        'task': 'tasks.embed_batch',
        'schedule': crontab(minute='*/5', hour='7-16'),
        'args': ('5min',)
    },
    'embedding_evening': {
        'task': 'tasks.embed_batch',
        'schedule': crontab(minute='*/30', hour='17-23'),
        'args': ('30min',)
    },
    'embedding_midnight': {
        'task': 'tasks.embed_batch',
        'schedule': crontab(minute='*/30', hour='0-6'),
        'args': ('30min_night',)
    }
}
tasks.embed_batch 내부 로직:
DB에서 is_embedded=False인 레코드들 가져오기.
OpenAI Embedding → Pinecone 업서트.
성공하면 is_embedded=True로 표시.
5. 상세 흐름 (정리)
(실시간) 텔레그램 메시지 수집

Telethon 이벤트 핸들러 → DB telegram_messages 테이블에 INSERT.
(옵션) 첨부파일이 있으면 GCS에 업로드 → file_url 저장.
종목 추출: stocks=["삼성전자","SK하이닉스"] 등.
(배치) Celery Beat

07:00~16:59 → 5분마다 embed_batch 태스크 실행
17:00~06:59 → 30분마다 embed_batch 실행
embed_batch는 DB에서 새 메시지 → OpenAI Embedding → Pinecone 인덱스 업서트(메타데이터: date, stocks, file_url, text).
(사용자 요청) 검색 & 요약

예: “오늘 삼성전자 요약”
Pinecone filter={"date":"2025-01-31","stocks":{"$in":["삼성전자"]}} or 유사도 쿼리
결과 메시지들의 본문을 LLM(GPT)에게 던져 “하루치 뉴스 요약” → 최종 결과 반환
첨부파일 있으면 해당 메시지의 file_url을 함께 노출. (iFrame/다운로드 링크)
PDF/문서 RAG

텔레그램 메시지에서 추출된 PDF는 별도 RAG 시스템에 임베딩, 여기선 단순히 URL 표시만.
사용자가 PDF 내용을 검색하려면 그쪽 시스템을 사용(혹은 통합).
운영/확장 고려

메시지가 폭주하면 5분 배치도 부하가 높아질 수 있음 → 적절한 서버 리소스, 초당 API 제한(레이트 리밋) 고려.
토큰 사용량(임베딩 + 요약) 비용 모니터링.
한 메시지에 여러 종목 있을 때, stocks 배열로 저장 → 검색 시 $in 필터.
6. 결론
텔레그램 메시지를 주식 종목별·날짜별로 임베딩(Pinecone) 하고,
검색 시 메타데이터 필터와 (필요하다면) 유사도 검색을 이용해 LLM(GPT 등)으로 요약,
첨부 PDF 등은 별도 RAG 시스템에서 처리하되, 텔레그램 측에서는 URL로 iFrame 표기만 담당.
스케줄은 Celery로: 07:00~17:00(오후5시) 사이엔 5분 간격, 그 외 시간대엔 30분 간격으로 임베딩.
이 모든 과정을 통해, 아침~장중엔 신속히(최대 5분 지연) 최신 정보가 검색·요약에 반영되고, 장마감 이후에는 여유 있는 30분 간격으로 효율적 운영이 가능합니다.