"""ê²½ëŸ‰ ë…¸ì…˜ í¬ë¡¤ëŸ¬ - Playwright ì‚¬ìš©"""

import asyncio
import re
from typing import Optional

try:
    from playwright.async_api import async_playwright
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    print("âš ï¸ Playwrightê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ëª…ë ¹ì–´: pip install playwright && playwright install chromium")

class LightNotionCrawler:
    """ê²½ëŸ‰ ë…¸ì…˜ í¬ë¡¤ëŸ¬ - Playwright ì‚¬ìš©"""
    
    def __init__(self):
        self.timeout = 30000  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
    
    async def crawl_notion_page(self, url: str) -> Optional[str]:
        """ë…¸ì…˜ í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            url (str): í¬ë¡¤ë§í•  ë…¸ì…˜ URL
            
        Returns:
            Optional[str]: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ë˜ëŠ” None
        """
        if not PLAYWRIGHT_AVAILABLE:
            print("âŒ Playwrightê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            print(f"ğŸ” Playwrightë¡œ ë…¸ì…˜ í¬ë¡¤ë§ ì‹œì‘: {url}")
            
            async with async_playwright() as p:
                # Chromium ë¸Œë¼ìš°ì € ì‹¤í–‰ (ê²½ëŸ‰)
                browser = await p.chromium.launch(
                    headless=True,
                    args=[
                        '--no-sandbox',
                        '--disable-dev-shm-usage',
                        '--disable-gpu',
                        '--disable-web-security',
                        '--disable-setuid-sandbox',
                        '--disable-dev-tools'
                    ]
                )
                
                page = await browser.new_page()
                
                # User-Agent ì„¤ì •
                await page.set_extra_http_headers({
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                })
                
                # í˜ì´ì§€ ë¡œë“œ
                await page.goto(url, wait_until='networkidle', timeout=self.timeout)
                
                # í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
                await page.wait_for_timeout(3000)
                
                # ë…¸ì…˜ ì½˜í…ì¸  ì˜ì—­ì„ ì°¾ê¸° ìœ„í•œ ì„ íƒìë“¤
                content_selectors = [
                    '[data-block-id]',  # ë…¸ì…˜ ë¸”ë¡
                    '.notion-page-content',
                    '.notion-page-block',
                    '[role="main"]',
                    'main',
                    'article'
                ]
                
                extracted_texts = []
                
                # ê° ì„ íƒìë¡œ ì½˜í…ì¸  ì°¾ê¸°
                for selector in content_selectors:
                    try:
                        elements = await page.query_selector_all(selector)
                        if elements:
                            print(f"âœ… ë°œê²¬ëœ ìš”ì†Œ ({selector}): {len(elements)}ê°œ")
                            
                            for element in elements[:20]:  # ìƒìœ„ 20ê°œë§Œ ì²˜ë¦¬
                                try:
                                    text = await element.inner_text()
                                    if text and len(text.strip()) > 10:  # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ
                                        extracted_texts.append(text.strip())
                                except Exception:
                                    continue
                            
                            if extracted_texts:
                                break  # ì½˜í…ì¸ ë¥¼ ì°¾ì•˜ìœ¼ë©´ ë‹¤ë¥¸ ì„ íƒìëŠ” ì‹œë„í•˜ì§€ ì•ŠìŒ
                                
                    except Exception as e:
                        print(f"âš ï¸ ì„ íƒì {selector} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        continue
                
                # ë¸Œë¼ìš°ì € ì¢…ë£Œ
                await browser.close()
                
                if extracted_texts:
                    # í…ìŠ¤íŠ¸ë“¤ì„ ê²°í•©
                    final_text = '\n\n'.join(extracted_texts)
                    
                    # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
                    lines = []
                    seen = set()
                    for line in final_text.split('\n'):
                        clean_line = line.strip()
                        if clean_line and len(clean_line) > 5 and clean_line not in seen:
                            lines.append(clean_line)
                            seen.add(clean_line)
                    
                    result = '\n'.join(lines)
                    print(f"âœ… ë…¸ì…˜ í¬ë¡¤ë§ ì„±ê³µ: {len(result)} ë¬¸ì ì¶”ì¶œ")
                    return result
                else:
                    print("âŒ ë…¸ì…˜ ì½˜í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return None
                    
        except Exception as e:
            print(f"âŒ ë…¸ì…˜ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_playwright_crawler():
    """Playwright í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸"""
    crawler = LightNotionCrawler()
    
    test_url = "https://sequoia-ray-2fa.notion.site/1f732f6a257980a0a95ad7126bc0e46e?pvs=4"
    result = await crawler.crawl_notion_page(test_url)
    
    if result:
        print(f"í¬ë¡¤ë§ ê²°ê³¼ (ì²˜ìŒ 500ì):\n{result[:500]}")
    else:
        print("í¬ë¡¤ë§ ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(test_playwright_crawler()) 