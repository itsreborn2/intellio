import logging
import re  # ì •ê·œì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
import warnings

import fitz  # PyMuPDF ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd  # DataFrame ë¼ì´ë¸ŒëŸ¬ë¦¬
from dotenv import load_dotenv

# markdownì„ htmlë¡œ ë³€í™˜í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
# OpenAI ëª¨ë¸ ì„í¬íŠ¸ ì¶”ê°€
# from langchain_openai import ChatOpenAI
from loguru import logger

warnings.filterwarnings("ignore", category=UserWarning, module="pdfminer")
warnings.filterwarnings("ignore", category=UserWarning, module="pdfplumber")
warnings.filterwarnings("ignore", category=UserWarning, module="fitz")  # PyMuPDF ê²½ê³  ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore", message="CropBox missing from /Page, defaulting to MediaBox")

# fitz ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ê²½ê³  ì¶œë ¥ ë ˆë²¨ ë³€ê²½ (0: ëª¨ë“  ì¶œë ¥, 1: ê²½ê³ ë§Œ, 2: ì˜¤ë¥˜ë§Œ, 3: ëª¨ë‘ ì–µì œ)
# ëª¨ë“  ê²½ê³  ë©”ì‹œì§€ ì–µì œ
fitz.TOOLS.mupdf_warnings_handler = lambda warn_level, message: None
# # ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),  # ì½˜ì†” ì¶œë ¥ìš© í•¸ë“¤ëŸ¬
    ],
)
logger2 = logging.getLogger(__name__)
logger2.setLevel(logging.INFO)  # ëª…ì‹œì ìœ¼ë¡œ INFO ë ˆë²¨ ì„¤ì •
logging.getLogger("pdfminer").setLevel(logging.ERROR)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def extract_unit_info(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ìœ„ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        text: í…ìŠ¤íŠ¸

    Returns:
        str: ì¶”ì¶œëœ ë‹¨ìœ„ ì •ë³´ (ì˜ˆ: "ë‹¨ìœ„: ì›", "ë‹¨ìœ„: ì‹­ì–µì›, USD")
    """
    if not text:
        return ""

    # ì „ê°/ë°˜ê° ë¬¸ì ì •ê·œí™” ë° íŠ¹ìˆ˜ ê³µë°± ì²˜ë¦¬
    normalized_text = text.replace("\u3000", " ")  # ì „ê° ìŠ¤í˜ì´ìŠ¤
    normalized_text = normalized_text.replace("\xa0", " ")  # NBSP
    normalized_text = normalized_text.replace("ï¼ˆ", "(").replace("ï¼‰", ")")  # ì „ê° ê´„í˜¸
    normalized_text = normalized_text.replace("ï¼š", ":")  # ì „ê° ì½œë¡ 
    normalized_text = normalized_text.replace("ï¼»", "[").replace("ï¼½", "]")  # ì „ê° ëŒ€ê´„í˜¸
    normalized_text = " ".join(normalized_text.split())  # ì—°ì† ê³µë°± ì •ë¦¬

    # ë‹¨ìœ„ ì •ë³´ë¥¼ ì°¾ëŠ” ì •ê·œì‹ íŒ¨í„´ë“¤ (ê°œì„ ëœ ë²„ì „)
    unit_patterns = [
        # ê´„í˜¸ íŒ¨í„´: (ë‹¨ìœ„: ì›), (ë‹¨ìœ„ : ì‹­ì–µì›, USD), (ë‹¨ìœ„ : ë°±ë§ŒUSD)
        r"\(\s*ë‹¨ìœ„\s*[:\s]\s*([^)]+)\)",
        # ëŒ€ê´„í˜¸ íŒ¨í„´: [ë‹¨ìœ„: ì›], [ë‹¨ìœ„ : ë°±ë§ŒUSD]
        r"\[\s*ë‹¨ìœ„\s*[:\s]\s*([^\]]+)\]",
        # í™”ì‚´ê´„í˜¸ íŒ¨í„´: <ë‹¨ìœ„: ì›>
        r"<\s*ë‹¨ìœ„\s*[:\s]\s*([^>]+)>",
        # ì¼ë°˜ íŒ¨í„´: ë‹¨ìœ„: ì›, ë‹¨ìœ„ : ì‹­ì–µì› (ì¤„ë°”ê¿ˆì´ë‚˜ ì‰¼í‘œ ì „ê¹Œì§€)
        r"ë‹¨ìœ„\s*[:\s]\s*([^,\n\r\t]+)",
    ]

    # logger.debug(f"ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ ì‹œë„: ì›ë³¸í…ìŠ¤íŠ¸='{text[:100]}...' ì •ê·œí™”í…ìŠ¤íŠ¸='{normalized_text[:100]}...'")

    for i, pattern in enumerate(unit_patterns):
        try:
            matches = re.findall(pattern, normalized_text, re.IGNORECASE)
            if matches:
                # ê°€ì¥ ì²« ë²ˆì§¸ ë§¤ì¹˜ ë°˜í™˜, ì•ë’¤ ê³µë°± ì œê±°
                unit = matches[0].strip()
                # logger.debug(f"ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ ì„±ê³µ: íŒ¨í„´{i + 1} '{pattern}' -> '{unit}'")
                return f"ë‹¨ìœ„: {unit}"
            # else:
            #     logger.debug(f"ë‹¨ìœ„ ì •ë³´ íŒ¨í„´{i + 1} ë§¤ì¹­ ì‹¤íŒ¨: '{pattern}'")
        except Exception as e:
            logger.debug(f"ë‹¨ìœ„ ì •ë³´ íŒ¨í„´{i + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

    # logger.debug("ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: ëª¨ë“  íŒ¨í„´ì—ì„œ ë§¤ì¹­ë˜ì§€ ì•ŠìŒ")
    return ""


def get_max_abs_value_from_dataframe(df: pd.DataFrame) -> float:
    """
    DataFrameì—ì„œ ìˆ«ì ê°’ ì¤‘ ìµœëŒ€ ì ˆëŒ“ê°’ì„ êµ¬í•©ë‹ˆë‹¤.

    Args:
        df: ë¶„ì„í•  DataFrame

    Returns:
        float: ìµœëŒ€ ì ˆëŒ“ê°’
    """
    max_abs_val = 0
    for col in df.columns:
        for idx in df.index:
            val_str = str(df.at[idx, col])
            if is_numeric_value(val_str):
                try:
                    clean_val = val_str.replace(",", "").replace("(", "").replace(")", "")
                    if clean_val.startswith("-"):
                        clean_val = clean_val[1:]
                    num_val = float(clean_val)
                    if abs(num_val) > max_abs_val:
                        max_abs_val = abs(num_val)
                except Exception:
                    pass
    return max_abs_val


def parse_unit_to_multiplier(unit_str: str) -> float:
    """
    ë‹¨ìœ„ ë¬¸ìì—´ì„ ë°°ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        unit_str: ë‹¨ìœ„ ë¬¸ìì—´ (ì˜ˆ: "ë°±ë§Œì›", "ì‹­ì–µì›", "ì¡°ì›")

    Returns:
        float: ë°°ìˆ˜ (ì˜ˆ: ë°±ë§Œì› -> 1000000, ì‹­ì–µì› -> 1000000000)
    """
    if not unit_str:
        return 1.0

    unit_str = unit_str.lower().strip()

    # ë‹¨ìœ„ ë§¤í•‘ (ê¸´ ë‹¨ìœ„ë¶€í„° ë§¤ì¹­í•˜ê¸° ìœ„í•´ ê¸¸ì´ ìˆœìœ¼ë¡œ ì •ë ¬)
    unit_multipliers = {
        "ì‹­ì¡°ì›": 10000000000000,
        "ì¡°ì›": 1000000000000,
        "ì²œì–µì›": 100000000000,
        "ë°±ì–µì›": 10000000000,
        "ì‹­ì–µì›": 1000000000,
        "ì–µì›": 100000000,
        "ì²œë§Œì›": 10000000,
        "ë°±ë§Œì›": 1000000,
        "ì‹­ë§Œì›": 100000,
        "ë§Œì›": 10000,
        "ì²œì›": 1000,
        "ë°±ì›": 100,
        "ì‹­ì›": 10,
        "ì›": 1,
        # ì˜ì–´ ë‹¨ìœ„
        "trillion": 1000000000000,
        "billion": 1000000000,
        "million": 1000000,
    }

    # ê¸¸ì´ê°€ ê¸´ ë‹¨ìœ„ë¶€í„° ë§¤ì¹­ (ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´)
    for unit, multiplier in unit_multipliers.items():
        if unit in unit_str:
            return multiplier

    return 1.0


def remove_unit_from_text(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ìœ„ ì •ë³´ ë¬¸ìì—´ì„ ì œê±°í•©ë‹ˆë‹¤.
    ì˜ˆ: (ë‹¨ìœ„: ë°±ë§Œì›) -> ""

    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸

    Returns:
        str: ë‹¨ìœ„ ì •ë³´ê°€ ì œê±°ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""

    unit_patterns = [
        r"\s*\(ë‹¨ìœ„[:\s]*[^)]+\)",  # (ë‹¨ìœ„: ì›)
        r"\s*ë‹¨ìœ„[:\s]*[^,\n\r]+",  # ë‹¨ìœ„: ì›
        r"\s*\[ë‹¨ìœ„[:\s]*[^\]]+\]",  # [ë‹¨ìœ„: ì›]
        r"\s*<ë‹¨ìœ„[:\s]*[^>]+>",  # <ë‹¨ìœ„: ì›>
    ]

    for pattern in unit_patterns:
        text = re.sub(pattern, "", text, flags=re.IGNORECASE)

    return text.strip()


def replace_unit_in_text(original_text: str, old_unit_name: str, new_unit_name: str) -> str:
    """
    í…ìŠ¤íŠ¸ ë‚´ì—ì„œ 'ë‹¨ìœ„:'ì™€ ê°™ì€ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¤„ì˜ ë‹¨ìœ„ë§Œ ì •í™•í•˜ê²Œ êµì²´í•©ë‹ˆë‹¤.
    ì˜ˆ: (ë‹¨ìœ„ : ë°±ë§Œì›) -> (ë‹¨ìœ„ : ì‹­ì–µì›)

    Args:
        original_text (str): ì›ë³¸ í…ìŠ¤íŠ¸.
        old_unit_name (str): êµì²´ë  ê¸°ì¡´ ë‹¨ìœ„ ì´ë¦„ (ì˜ˆ: "ë°±ë§Œì›").
        new_unit_name (str): ìƒˆë¡œ ì ìš©ë  ë‹¨ìœ„ ì´ë¦„ (ì˜ˆ: "ì‹­ì–µì›").

    Returns:
        str: ë‹¨ìœ„ê°€ êµì²´ëœ í…ìŠ¤íŠ¸.
    """
    if not all([original_text, old_unit_name, new_unit_name]):
        return original_text

    import re

    lines = original_text.split("\n")
    new_lines = []

    for line in lines:
        # 'ë‹¨ìœ„' í‚¤ì›Œë“œê°€ ìˆëŠ” ì¤„ì—ì„œë§Œ êµì²´ë¥¼ ì‹œë„
        if "ë‹¨ìœ„" in line:
            # ë‹¨ìœ„ íŒ¨í„´ì„ ì •í™•í•˜ê²Œ ë§¤ì¹­í•˜ì—¬ êµì²´: ê³µë°± í—ˆìš© íŒ¨í„´
            # ( ë‹¨ìœ„ : ë°±ë§Œì›), (ë‹¨ìœ„: ë°±ë§Œì›), ( ë‹¨ìœ„: ë°±ë§Œì›) ë“± ëª¨ë“  í˜•íƒœ ì§€ì›
            unit_patterns = [
                # ê¸°ë³¸ íŒ¨í„´: ( ë‹¨ìœ„ : ë°±ë§Œì›) - ( ë’¤ì™€ ë‹¨ìœ„ ë’¤ ëª¨ë‘ ê³µë°± í—ˆìš©
                r"(\(\s*ë‹¨ìœ„\s*:\s*)" + re.escape(old_unit_name) + r"(\s*\))",
                # ë³µí•© íŒ¨í„´: ( ë‹¨ìœ„ : ë°±ë§Œì›, USD) - ë³µí•© ë‹¨ìœ„ë„ ê³µë°± í—ˆìš©
                r"(\(\s*ë‹¨ìœ„\s*:\s*)" + re.escape(old_unit_name) + r"(\s*,.*?\))",
                # ê´„í˜¸ ì—†ëŠ” íŒ¨í„´: ë‹¨ìœ„ : ë°±ë§Œì› - ê´„í˜¸ ì—†ì´ë„ ê³µë°± í—ˆìš©
                r"(ë‹¨ìœ„\s*:\s*)" + re.escape(old_unit_name) + r"(\s*(?:[,\n]|$))",
            ]

            replaced = False
            for i, pattern in enumerate(unit_patterns):
                if re.search(pattern, line):
                    new_line = re.sub(pattern, r"\1" + new_unit_name + r"\2", line)
                    logger.debug(f"ë‹¨ìœ„ êµì²´ íŒ¨í„´ {i + 1} ë§¤ì¹˜: '{line.strip()}' â†’ '{new_line.strip()}'")
                    new_lines.append(new_line)
                    replaced = True
                    break

            if not replaced:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ë…ë¦½ì ì¸ ë‹¨ìœ„ë§Œ êµì²´ (ì ‘ë‘ì‚¬ê°€ ìˆëŠ” ê²½ìš° ì œì™¸)
                # ì˜ˆ: "ì›"ì„ "ë°±ë§Œì›"ìœ¼ë¡œ ë°”ê¿€ ë•Œ "ì‹­ì–µì›"ì˜ "ì›"ì€ êµì²´í•˜ì§€ ì•ŠìŒ
                if old_unit_name in line and new_unit_name not in line:
                    # ë…ë¦½ì ì¸ ë‹¨ìœ„ì¸ì§€ í™•ì¸ (ì•ì— ë‹¤ë¥¸ ë‹¨ìœ„ê°€ ë¶™ì–´ìˆì§€ ì•Šì€ì§€)
                    import re

                    # ë‹¨ìœ„ ì•ì— ë‹¤ë¥¸ ë¬¸ì(í•œê¸€/ìˆ«ì)ê°€ ë¶™ì–´ìˆìœ¼ë©´ êµì²´í•˜ì§€ ì•ŠìŒ
                    independent_pattern = r"(?<![ê°€-í£\d])" + re.escape(old_unit_name) + r"(?![ê°€-í£\d])"
                    if re.search(independent_pattern, line):
                        logger.debug(f"ë‹¨ìœ„ êµì²´ fallback: '{line.strip()}' â†’ '{re.sub(independent_pattern, new_unit_name, line).strip()}'")
                        new_lines.append(re.sub(independent_pattern, new_unit_name, line))
                    else:
                        logger.debug(f"ë‹¨ìœ„ êµì²´ ê±´ë„ˆëœ€: '{line.strip()}' (ë…ë¦½ì ì´ì§€ ì•Šì€ ë‹¨ìœ„ - ì ‘ë‘ì‚¬ ì¡´ì¬)")
                        new_lines.append(line)
                else:
                    logger.debug(f"ë‹¨ìœ„ êµì²´ ê±´ë„ˆëœ€: '{line.strip()}' (ì´ë¯¸ {new_unit_name} í¬í•¨ ë˜ëŠ” {old_unit_name} ì—†ìŒ)")
                    new_lines.append(line)
        else:
            new_lines.append(line)
    return "\n".join(new_lines)


def is_numeric_value(value: str) -> bool:
    """
    ë¬¸ìì—´ì´ ìˆ«ì ê°’ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.

    Args:
        value: í™•ì¸í•  ë¬¸ìì—´

    Returns:
        bool: ìˆ«ì ê°’ ì—¬ë¶€
    """
    if not isinstance(value, str):
        logger.debug(f"is_numeric_value: ì˜ëª»ëœ ì…ë ¥ íƒ€ì… - {value} ({type(value)})")
        return False

    # ê³µë°± ì œê±°
    value = value.strip()

    # ë¹ˆ ë¬¸ìì—´ ì²´í¬
    if not value:
        # logger.debug("is_numeric_value: ë¹ˆ ë¬¸ìì—´")
        return False

    # í¼ì„¼íŠ¸ ê¸°í˜¸ê°€ ìˆìœ¼ë©´ ìˆ«ìê°€ ì•„ë‹˜
    if "%" in value:
        # logger.debug(f"is_numeric_value: í¼ì„¼íŠ¸ ê°’ - {value}")
        return False

    # ì‰¼í‘œ ì œê±°í•˜ê³  ìˆ«ì í™•ì¸
    clean_value = value.replace(",", "").replace("(", "").replace(")", "")

    # ìŒìˆ˜ ì²˜ë¦¬ (ê´„í˜¸ ë˜ëŠ” ë§ˆì´ë„ˆìŠ¤)
    if value.startswith("(") and value.endswith(")"):
        clean_value = "-" + clean_value
    elif clean_value.startswith("-"):
        pass

    try:
        float(clean_value)
        # logger.debug(f"is_numeric_value: ìˆ«ì ì¸ì‹ ì„±ê³µ - {value} -> {clean_value}")
        return True
    except ValueError:
        # logger.debug(f"is_numeric_value: ìˆ«ì ì¸ì‹ ì‹¤íŒ¨ - {value}")
        return False


def convert_value_to_target_unit(value: str, source_multiplier: float, target_multiplier: float) -> str:
    """
    ê°’ì„ ì†ŒìŠ¤ ë‹¨ìœ„ì—ì„œ íƒ€ê²Ÿ ë‹¨ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        value: ë³€í™˜í•  ê°’ (ë¬¸ìì—´)
        source_multiplier: ì†ŒìŠ¤ ë‹¨ìœ„ì˜ ë°°ìˆ˜
        target_multiplier: íƒ€ê²Ÿ ë‹¨ìœ„ì˜ ë°°ìˆ˜

    Returns:
        str: ë³€í™˜ëœ ê°’ (ë¬¸ìì—´)
    """

    # logger.debug(f"convert_value_to_target_unit ì‹œì‘: value='{value}', source_multiplier={source_multiplier}, target_multiplier={target_multiplier}")

    if not is_numeric_value(value):
        # logger.debug(f"convert_value_to_target_unit: ìˆ«ìê°€ ì•„ë‹˜, ì›ë³¸ ë°˜í™˜ - '{value}'")
        return value

    try:
        # ì‰¼í‘œ ì œê±° ë° ê´„í˜¸ ì²˜ë¦¬
        clean_value = value.replace(",", "")
        is_negative = False

        if clean_value.startswith("(") and clean_value.endswith(")"):
            clean_value = clean_value[1:-1]
            is_negative = True
        elif clean_value.startswith("-"):
            is_negative = True
            clean_value = clean_value[1:]

        # logger.debug(f"convert_value_to_target_unit: clean_value='{clean_value}', is_negative={is_negative}")

        # ìˆ«ìë¡œ ë³€í™˜
        numeric_value = float(clean_value)

        # ìŒìˆ˜ ì²˜ë¦¬
        if is_negative:
            numeric_value = -numeric_value

        # ë‹¨ìœ„ ë³€í™˜
        converted_value = numeric_value * source_multiplier / target_multiplier

        # í¬ë§·íŒ…
        if converted_value == 0:
            formatted = "0"
        elif abs(converted_value) >= 1000:  # 1000 ì´ìƒì´ë©´, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì •ìˆ˜ë¡œ í‘œì‹œ
            formatted = f"{round(converted_value):,.0f}"
        elif abs(converted_value) >= 10:  # 10 ì´ìƒì´ë©´, ì†Œìˆ˜ì  1ìë¦¬
            formatted = f"{converted_value:,.1f}".rstrip("0").rstrip(".")
        else:
            formatted = f"{converted_value:.2f}".rstrip("0").rstrip(".")
        return formatted

    except Exception as e:
        logger.debug(f"convert_value_to_target_unit: ë³€í™˜ ì˜¤ë¥˜ {value} -> {str(e)}")
        return value


def convert_dataframe_units(df: pd.DataFrame, source_unit: str, target_unit: str = "ì‹­ì–µì›") -> pd.DataFrame:
    """
    DataFrameì˜ ìˆ«ì ë°ì´í„°ë¥¼ ë‹¤ë¥¸ ë‹¨ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        df: ë³€í™˜í•  DataFrame
        source_unit: ì†ŒìŠ¤ ë‹¨ìœ„ ì •ë³´ (ì˜ˆ: "ë‹¨ìœ„: ë°±ë§Œì›")
        target_unit: íƒ€ê²Ÿ ë‹¨ìœ„ (ì˜ˆ: "ì‹­ì–µì›")

    Returns:
        pd.DataFrame: ë‹¨ìœ„ê°€ ë³€í™˜ëœ DataFrame
    """
    if not isinstance(df, pd.DataFrame) or df.empty:
        return df

    # ì†ŒìŠ¤ ë‹¨ìœ„ì—ì„œ ì‹¤ì œ ë‹¨ìœ„ ì¶”ì¶œ
    source_unit_full = source_unit.replace("ë‹¨ìœ„:", "").replace("ë‹¨ìœ„ :", "").strip()
    source_unit_parts = [p.strip() for p in source_unit_full.split(",")]
    source_unit_clean = source_unit_parts[0]

    # ì™¸í™” ë‹¨ìœ„ í™•ì¸ (ë³€í™˜í•˜ì§€ ì•ŠìŒ)
    foreign_currencies = ["usd", "eur", "jpy", "cny", "gbp", "krw", "dollar", "euro", "yen", "yuan", "pound"]
    source_unit_lower = source_unit_clean.lower()

    # ì™¸í™” ë‹¨ìœ„ê°€ í¬í•¨ëœ ê²½ìš° ë³€í™˜í•˜ì§€ ì•Šê³  ì›ë³¸ DataFrame ë°˜í™˜
    if any(currency in source_unit_lower for currency in foreign_currencies):
        # logger.debug(f"ì™¸í™” ë‹¨ìœ„ ê°ì§€: '{source_unit_clean}' - ë‹¨ìœ„ ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤")
        # ì›ë³¸ DataFrameì„ ë³µì‚¬í•˜ë˜ ë‹¨ìœ„ ì •ë³´ë§Œ ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ê°€
        result_df = df.copy()
        result_df.attrs["original_unit"] = source_unit
        result_df.attrs["converted_unit"] = source_unit  # ë³€í™˜í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì›ë³¸ ë‹¨ìœ„ ìœ ì§€
        return result_df

    # ë‹¨ìœ„ ë°°ìˆ˜ ê³„ì‚°
    source_multiplier = parse_unit_to_multiplier(source_unit_clean)
    target_multiplier = parse_unit_to_multiplier(target_unit)

    # ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ë‹¨ìœ„ì¸ ê²½ìš° (source_multiplierê°€ 1.0ì¸ ê²½ìš°)
    if source_multiplier == 1.0 and source_unit_clean.lower() not in ["ì›", "won"]:
        # logger.debug(f"ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ìœ„: '{source_unit_clean}' - ë‹¨ìœ„ ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤")
        result_df = df.copy()
        result_df.attrs["original_unit"] = source_unit
        result_df.attrs["converted_unit"] = source_unit
        return result_df

    # logger.debug(f"ë‹¨ìœ„ ë³€í™˜: {source_unit_clean} ({source_multiplier:,}) -> {target_unit} ({target_multiplier:,})")

    # pandas DataFrameì˜ ì™„ì „í•œ ë³µì‚¬ (ìƒˆë¡œìš´ ë…ë¦½ ê°ì²´ ìƒì„±)
    converted_df = pd.DataFrame(df.values.copy(), columns=df.columns.copy(), index=df.index.copy())

    # logger.debug(f"ë³€í™˜ ì‹œì‘ - ì›ë³¸ DataFrame í¬ê¸°: {df.shape}")
    # logger.debug(f"ë³€í™˜ìš© DataFrame ID: {id(converted_df)}, ì›ë³¸ DataFrame ID: {id(df)}")
    # logger.debug(f"DataFrame ë…ë¦½ì„± í™•ì¸: {id(converted_df) != id(df)}")

    # ê° ì…€ì— ëŒ€í•´ ë³€í™˜ ìˆ˜í–‰
    conversion_count = 0
    for col in converted_df.columns:
        for idx in converted_df.index:
            original_value = converted_df.at[idx, col]
            if pd.isna(original_value) or original_value == "":
                continue

            original_str = str(original_value)
            converted_value = convert_value_to_target_unit(original_str, source_multiplier, target_multiplier)

            # ë³€í™˜ì´ ì‹¤ì œë¡œ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸
            if converted_value != original_str:
                conversion_count += 1
                # logger.debug(f"ì…€ ë³€í™˜: [{idx}, '{col}'] '{original_str}' -> '{converted_value}'")

                # ì‹¤ì œ DataFrameì— ê°’ í• ë‹¹
                converted_df.at[idx, col] = converted_value

                # í• ë‹¹ í›„ ê°’ í™•ì¸
                assigned_value = converted_df.at[idx, col]
                # logger.debug(f"í• ë‹¹ í™•ì¸: [{idx}, '{col}'] ì„¤ì •ê°’: '{converted_value}' ì‹¤ì œê°’: '{assigned_value}'")

    # logger.debug(f"ì´ {conversion_count}ê°œ ì…€ì´ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ë³€í™˜ ì™„ë£Œ í›„ ìƒ˜í”Œ ê°’ í™•ì¸
    if conversion_count > 0:
        sample_row = 0
        for col in converted_df.columns:
            val = converted_df.at[sample_row, col] if sample_row < len(converted_df) else None
            if val and is_numeric_value(str(val)):
                # logger.debug(f"ë³€í™˜ ì™„ë£Œ ìƒ˜í”Œ í™•ì¸: [{sample_row}, '{col}'] = '{val}'")
                break

    # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    new_unit_parts = [target_unit] + source_unit_parts[1:]
    new_unit_full = ", ".join(new_unit_parts)
    converted_df.attrs["original_unit"] = source_unit
    converted_df.attrs["converted_unit"] = f"ë‹¨ìœ„: {new_unit_full}"

    # ìµœì¢… ê²€ì¦: ë³€í™˜ì´ ì œëŒ€ë¡œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
    # logger.debug("=== ë³€í™˜ ê²°ê³¼ ìµœì¢… ê²€ì¦ ===")
    verification_count = 0
    for col in converted_df.columns:
        for idx in converted_df.index:
            current_value = converted_df.at[idx, col]
            if current_value and is_numeric_value(str(current_value)):
                original_in_df = df.at[idx, col] if idx in df.index and col in df.columns else None
                # logger.debug(f"ê²€ì¦: [{idx}, '{col}'] ì›ë³¸='{original_in_df}' í˜„ì¬='{current_value}'")
                verification_count += 1
                if verification_count >= 3:  # ì²˜ìŒ 3ê°œë§Œ ê²€ì¦
                    break
        if verification_count >= 3:
            break
    # logger.debug("=== ê²€ì¦ ì™„ë£Œ ===")

    return converted_df


def dataframe_to_markdown(df: pd.DataFrame, table_id: int = 1, source: str = "") -> str:
    """
    DataFrameì„ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        df: ë³€í™˜í•  DataFrame
        table_id: í…Œì´ë¸” ID

    Returns:
        str: ë§ˆí¬ë‹¤ìš´ í˜•íƒœì˜ í…Œì´ë¸” ë¬¸ìì—´
    """
    if df.empty:
        return f"[í…Œì´ë¸” {table_id} - ë¹ˆ í…Œì´ë¸”]\n\n"

    markdown_content = ""

    # ë‹¨ìœ„ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€ (ë³€í™˜ëœ ë‹¨ìœ„ ìš°ì„ , ì—†ìœ¼ë©´ ì›ë³¸ ë‹¨ìœ„)
    unit_to_display = df.attrs.get("converted_unit") or df.attrs.get("unit_info", "")
    if source == "ìµœì¢…ë°ì´í„°" and unit_to_display:
        markdown_content += f"({str(unit_to_display).strip()})\n"

    # ì»¬ëŸ¼ í—¤ë” ì¶”ê°€
    if not df.columns.empty and len(df.columns) > 0:
        header_row = []
        for col in df.columns:
            header_row.append(str(col) if col and str(col).strip() else "")
        markdown_content += "| " + " | ".join(header_row) + " |\n"

        # êµ¬ë¶„ì„  ì¶”ê°€
        separator = ["---"] * len(header_row)
        markdown_content += "| " + " | ".join(separator) + " |\n"

    # ë°ì´í„° í–‰ ì¶”ê°€
    for idx, row in df.iterrows():
        row_data = []
        for value in row:
            if pd.isna(value) or value == "":
                row_data.append("")
            else:
                clean_value = str(value).strip()

                # ğŸ“‹ ê°œì„ : ë°ì´í„° í–‰ì—ì„œ í—¤ë”ëª…(Unnamed ì‹œë¦¬ì¦ˆ) ì œê±°
                if clean_value.startswith("Unnamed"):
                    row_data.append("")
                else:
                    row_data.append(clean_value)

        # ë¹ˆ í–‰ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
        if any(cell for cell in row_data if cell):
            markdown_content += "| " + " | ".join(row_data) + " |\n"

    markdown_content += "\n"
    return markdown_content


def create_dataframe_from_table(table_data: list, unit_info: str = "", has_header: bool = True):
    """
    í…Œì´ë¸” ë°ì´í„°ë¥¼ pandas DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    âš ï¸ ì´ í•¨ìˆ˜ëŠ” ë‹¨ìˆœíˆ 2ì°¨ì› ë°°ì—´ì„ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ë§Œ í•©ë‹ˆë‹¤.
    í—¤ë” íŒë‹¨ì€ ìƒìœ„ í•¨ìˆ˜ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê°€ì§€ê³  ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

    Args:
        table_data: 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ í…Œì´ë¸” ë°ì´í„°
        unit_info: ë‹¨ìœ„ ì •ë³´
        has_header: ì²« ë²ˆì§¸ í–‰ì´ í—¤ë”ì¸ì§€ ì—¬ë¶€ (ìƒìœ„ í•¨ìˆ˜ì—ì„œ ê²°ì •)

    Returns:
        pandas.DataFrame: ë³€í™˜ëœ DataFrame
    """
    if not table_data or len(table_data) == 0:
        return pd.DataFrame()

    try:
        # ë¹ˆ í–‰ ì œê±°
        cleaned_data = []
        for row in table_data:
            if row and any(cell for cell in row if cell and str(cell).strip()):
                # None ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ê° ì…€ ì •ë¦¬
                cleaned_row = []
                for cell in row:
                    if cell:
                        clean_cell = str(cell).strip().replace("\n", " ").replace("\r", "")
                        clean_cell = " ".join(clean_cell.split())
                        cleaned_row.append(clean_cell)
                    else:
                        cleaned_row.append("")
                cleaned_data.append(cleaned_row)

        if not cleaned_data:
            return pd.DataFrame()

        # DataFrame ìƒì„±
        df = pd.DataFrame(cleaned_data)

        # í—¤ë” ì²˜ë¦¬ (ìƒìœ„ í•¨ìˆ˜ì—ì„œ ê²°ì •ëœ has_header íŒŒë¼ë¯¸í„° ê¸°ë°˜)
        if has_header and len(cleaned_data) > 0:
            # ì»¬ëŸ¼ëª… ì„¤ì • ë° ì¤‘ë³µ ì²˜ë¦¬
            header = list(cleaned_data[0])
            new_header = []
            counts = {}
            for col in header:
                clean_col = col if col and str(col).strip() else "Unnamed"
                if clean_col in counts:
                    counts[clean_col] += 1
                    new_header.append(f"{clean_col}.{counts[clean_col]}")
                else:
                    counts[clean_col] = 1
                    new_header.append(clean_col)

            if len(cleaned_data) == 1:
                # í—¤ë”ë§Œ ìˆëŠ” í…Œì´ë¸”ì˜ ê²½ìš°
                df = pd.DataFrame([], columns=new_header)
                # logger.debug(f"DataFrame ìƒì„±: í—¤ë”ë§Œ ìˆëŠ” í…Œì´ë¸”. ì»¬ëŸ¼: {new_header}")
            else:
                # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°, ì²« í–‰ì„ í—¤ë”ë¡œ ì„¤ì •
                df.columns = new_header
                df = df.iloc[1:].reset_index(drop=True)
                # logger.debug(f"DataFrame ìƒì„±: ì²« í–‰ì„ í—¤ë”ë¡œ ì„¤ì •. ì»¬ëŸ¼: {new_header}")
        else:
            # í—¤ë” ì—†ìŒ - ê¸°ë³¸ ì»¬ëŸ¼ëª… ì‚¬ìš©
            logger.debug(f"DataFrame ìƒì„±: í—¤ë” ì—†ìŒ, ê¸°ë³¸ ì»¬ëŸ¼ëª… ì‚¬ìš©. í¬ê¸°: {df.shape}")

        # ë‹¨ìœ„ ì •ë³´ê°€ ìˆìœ¼ë©´ DataFrameì— ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ê°€
        if unit_info:
            df.attrs["unit_info"] = unit_info

        return df

    except Exception as e:
        logger.error(f"DataFrame ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()


def _clean_extracted_text(text: str) -> str:
    """
    ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ë¼ì¸ì„ ì œê±°í•©ë‹ˆë‹¤.

    Args:
        text: ì •ë¦¬í•  í…ìŠ¤íŠ¸

    Returns:
        str: ì •ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return text

    lines = text.split("\n")
    cleaned_lines = []

    for line in lines:
        # 'ì „ìê³µì‹œì‹œìŠ¤í…œ dart.fss.or.kr' ë¬¸êµ¬ê°€ ìˆëŠ” ë¼ì¸ ì œê±°
        if "ì „ìê³µì‹œì‹œìŠ¤í…œ dart.fss.or.kr" in line:
            continue
        cleaned_lines.append(line)

    return "\n".join(cleaned_lines)


def is_position_based_continuation(prev_table_info: dict, current_table_info: dict) -> bool:
    """
    ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ í…Œì´ë¸” ì—°ì†ì„±ì„ íŒë‹¨í•©ë‹ˆë‹¤ (ë ˆì´ì•„ì›ƒ ì¸ì‹ ê¸°ë°˜ ë¶„ì„).

    í˜ì´ì§€ ê°„ ì—°ì†ì„±ë¿ë§Œ ì•„ë‹ˆë¼ ê°™ì€ í˜ì´ì§€ ë‚´ì—ì„œë„ ë¬¼ë¦¬ì  ê±°ë¦¬ë¥¼ ê³ ë ¤í•©ë‹ˆë‹¤.

    Args:
        prev_table_info: ì´ì „ í…Œì´ë¸” ì •ë³´ (bbox í¬í•¨)
        current_table_info: í˜„ì¬ í…Œì´ë¸” ì •ë³´ (bbox í¬í•¨)

    Returns:
        bool: ìœ„ì¹˜ìƒ ì—°ì†ëœ í…Œì´ë¸”ì¸ì§€ ì—¬ë¶€
    """
    if not prev_table_info or not current_table_info:
        return False

    prev_bbox = prev_table_info.get("bbox")
    curr_bbox = current_table_info.get("bbox")
    prev_page = prev_table_info.get("page_num")
    curr_page = current_table_info.get("page_num")
    prev_pos = prev_table_info.get("table_position_in_page", 0)
    curr_pos = current_table_info.get("table_position_in_page", 0)

    if not prev_bbox or not curr_bbox or not prev_page or not curr_page:
        return False

    prev_bottom = prev_bbox[3]  # ì´ì „ í…Œì´ë¸” í•˜ë‹¨ Yì¢Œí‘œ
    curr_top = curr_bbox[1]  # í˜„ì¬ í…Œì´ë¸” ìƒë‹¨ Yì¢Œí‘œ
    page_height = 792  # ì¼ë°˜ì ì¸ A4 í˜ì´ì§€ ë†’ì´
    # ì´ì „ í…Œì´ë¸” í•˜ë‹¨=797.0, í˜„ì¬ í…Œì´ë¸” ìƒë‹¨=50.0 => í˜ì´ì§€ ì—°ì†ëœ ê°™ì€ í…Œì´ë¸”

    # ì¼€ì´ìŠ¤ 1: í˜ì´ì§€ ê°„ ì—°ì†ì„± (ê¸°ì¡´ ë¡œì§)
    if curr_page - prev_page == 1:
        # í˜„ì¬ í˜ì´ì§€ì˜ ì²« ë²ˆì§¸ í…Œì´ë¸”ì´ì–´ì•¼ í•¨
        if curr_pos != 0:
            return False

        # ì´ì „ í…Œì´ë¸”ì´ í˜ì´ì§€ í•˜ë‹¨ 70% ì´í›„ì— ìˆê³ 
        # í˜„ì¬ í…Œì´ë¸”ì´ í˜ì´ì§€ ìƒë‹¨ 30% ì´ì „ì— ìˆìœ¼ë©´ ì—°ì†ì„± ë†’ìŒ
        # prev_near_bottom = prev_bottom > (page_height * 0.85)
        # curr_near_top = curr_top < (page_height * 0.15)
        prev_near_bottom = prev_bottom > 740  # 600í¬ì¸íŠ¸. ë¹„ìœ¨ë§ê³ , ì ˆëŒ€ê°’ìœ¼ë¡œ íŒë‹¨í•´ë³´ì.
        curr_near_top = curr_top < 60  # 60í¬ì¸íŠ¸. ë¹„ìœ¨ë§ê³ , ì ˆëŒ€ê°’ìœ¼ë¡œ íŒë‹¨í•´ë³´ì.

        is_continuous = prev_near_bottom and curr_near_top

        # if is_continuous:
        #     logger.debug(f"[í˜ì´ì§€ê°„][{prev_page}~{curr_page}] ì¢Œí‘œ ê¸°ë°˜ ì—°ì†ì„± ê°ì§€: ì´ì „ í…Œì´ë¸” í•˜ë‹¨={prev_bottom:.1f}, í˜„ì¬ í…Œì´ë¸” ìƒë‹¨={curr_top:.1f}")
        # else:
        #     logger.debug(f"[í˜ì´ì§€ê°„][{prev_page}~{curr_page}] ì¢Œí‘œ ê¸°ë°˜ ì—°ì†ì„± ê±°ë¶€: ì´ì „ í…Œì´ë¸” í•˜ë‹¨={prev_bottom:.1f}, í˜„ì¬ í…Œì´ë¸” ìƒë‹¨={curr_top:.1f}")

        return is_continuous
    else:
        return False


def merge_continued_tables(prev_table_df: pd.DataFrame, current_table_df: pd.DataFrame) -> pd.DataFrame:
    """
    ì—°ê²°ëœ í…Œì´ë¸”ì„ ë³‘í•©í•©ë‹ˆë‹¤. ì»¬ëŸ¼ ìˆ˜ê°€ ë‹¤ë¥¸ ê²½ìš°, ìš”ì•½ í–‰ íŒ¨í„´ ë“±ì„ ê°ì§€í•˜ì—¬ ì •ë ¬ì„ ì‹œë„í•©ë‹ˆë‹¤.

    Args:
        prev_table_df: ì´ì „ í…Œì´ë¸” DataFrame
        current_table_df: í˜„ì¬ í…Œì´ë¸” DataFrame

    Returns:
        pd.DataFrame: ë³‘í•©ëœ DataFrame
    """
    if prev_table_df is None:
        return current_table_df

    if current_table_df is None or current_table_df.empty:
        return prev_table_df

    # í—¤ë”ë§Œ ìˆëŠ” í…Œì´ë¸”(empty=Trueì´ì§€ë§Œ ì»¬ëŸ¼ì€ ì¡´ì¬)ì´ê±°ë‚˜, ë°ì´í„°ê°€ ìˆëŠ” í…Œì´ë¸”ì„ ì²˜ë¦¬
    # ì™„ì „íˆ ë¹„ì–´ìˆëŠ” DataFrame(ì»¬ëŸ¼ë„ ì—†ìŒ)ë§Œ ê±´ë„ˆë›°ë„ë¡ ìˆ˜ì •
    if prev_table_df.empty and prev_table_df.columns.empty:
        return current_table_df

    try:
        # ğŸ“‹ ê°œì„ : ì‘ì—… ì‹œ ì›ë³¸ì´ ì•„ë‹Œ ë³µì‚¬ë³¸ ì‚¬ìš©
        prev_df_to_merge = prev_table_df.copy()
        current_df_to_merge = current_table_df.copy()

        prev_col_count = len(prev_df_to_merge.columns)
        curr_col_count = len(current_df_to_merge.columns)

        if prev_col_count != curr_col_count:
            logger.debug(f"í…Œì´ë¸” ë³‘í•©: ì»¬ëŸ¼ ê°œìˆ˜ê°€ ë‹¤ë¦„ - ì´ì „:{prev_col_count}, í˜„ì¬:{curr_col_count}")
            logger.debug(f"ì´ì „ í…Œì´ë¸”:\n{prev_df_to_merge.to_string()}")
            logger.debug(f"í˜„ì¬ í…Œì´ë¸”:\n{current_df_to_merge.to_string()}")

            # íŒ¨í„´ 1: í˜„ì¬ í…Œì´ë¸”ì´ 1ê°œ ì—´ì´ 'ì ì„' ë•Œ (ìš”ì•½ í–‰ ì¼€ì´ìŠ¤)
            if prev_col_count - curr_col_count == 1:
                is_summary_row = False
                if len(current_df_to_merge) == 1:
                    first_val = str(current_df_to_merge.iloc[0, 0]).strip()
                    if any(keyword in first_val for keyword in ["í•© ê³„", "í•©ê³„", "ì´ê³„", "ì†Œê³„"]):
                        is_summary_row = True

                if is_summary_row:
                    logger.info("ìš”ì•½ í–‰ ë³‘í•© íŒ¨í„´ ê°ì§€. í˜„ì¬ í…Œì´ë¸” ì»¬ëŸ¼ ì •ë ¬ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                    row_values = current_df_to_merge.iloc[0].tolist()
                    new_row_list = [row_values[0]] + [None] + row_values[1:]

                    if len(new_row_list) == prev_col_count:
                        aligned_df = pd.DataFrame([new_row_list], columns=prev_df_to_merge.columns)
                        current_df_to_merge = aligned_df
                        logger.info(f"ìš”ì•½ í–‰ ì •ë ¬ ì„±ê³µ. ë³‘í•©í•  ìƒˆ ë°ì´í„°:\n{current_df_to_merge.to_string()}")
                    else:
                        logger.warning(f"ìš”ì•½ í–‰ ì •ë ¬ ë¡œì§ ì‹¤íŒ¨: ìƒì„±ëœ í–‰ì˜ ì—´ ê°œìˆ˜({len(new_row_list)})ê°€ ì´ì „ í…Œì´ë¸”({prev_col_count})ê³¼ ë¶ˆì¼ì¹˜.")

            # íŒ¨í„´ 2: í˜„ì¬ í…Œì´ë¸”ì´ 1ê°œ ì—´ì´ 'ë§ì„' ë•Œ (ê³„ì¸µ êµ¬ì¡° ì¼€ì´ìŠ¤)
            elif curr_col_count - prev_col_count == 1:
                logger.info("ê³„ì¸µì  í…Œì´ë¸” ë³‘í•© íŒ¨í„´ ê°ì§€. ì´ì „ í…Œì´ë¸” ì»¬ëŸ¼ í™•ì¥ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                # ì´ì „ í…Œì´ë¸”ì˜ ë‘ ë²ˆì§¸ ìœ„ì¹˜ì— ë¹ˆ ì»¬ëŸ¼ ì‚½ì…
                # ì»¬ëŸ¼ëª…ì€ í˜„ì¬ í…Œì´ë¸”ì˜ ë‘ ë²ˆì§¸ ì»¬ëŸ¼ëª…ì„ ë”°ë¦„ (ë³´í†µ 'Unnamed' ë“±)
                new_col_name = current_df_to_merge.columns[1]
                prev_df_to_merge.insert(1, new_col_name, None)
                logger.info(f"ì´ì „ í…Œì´ë¸” í™•ì¥ ì„±ê³µ. ë³‘í•©í•  ìƒˆ ì´ì „ í…Œì´ë¸”:\n{prev_df_to_merge.to_string()}")

        # ë³‘í•© ì „, ë‘ DataFrameì˜ ì»¬ëŸ¼ì´ ë™ì¼í•œì§€ ë§ˆì§€ë§‰ìœ¼ë¡œ í™•ì¸í•˜ê³  ì„¤ì •
        if len(prev_df_to_merge.columns) == len(current_df_to_merge.columns):
            # êµ¬ì¡°ê°€ ì •ë ¬ë˜ì—ˆìœ¼ë¯€ë¡œ, ì´ì „ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ëª…ì„ ê°•ì œë¡œ ë™ê¸°í™”
            current_df_to_merge.columns = prev_df_to_merge.columns
        else:
            logger.warning(f"ë³‘í•© ì „ ì»¬ëŸ¼ ìˆ˜ ë¶ˆì¼ì¹˜: ì´ì „({len(prev_df_to_merge.columns)}), í˜„ì¬({len(current_df_to_merge.columns)}). ë³‘í•© ê²°ê³¼ê°€ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # DataFrame ë³‘í•©
        merged_df = pd.concat([prev_df_to_merge, current_df_to_merge], ignore_index=True)

        # ë©”íƒ€ë°ì´í„° ë³´ì¡´
        merged_df.attrs = prev_table_df.attrs.copy()

        # logger.debug(f"í…Œì´ë¸” ë³‘í•© ì™„ë£Œ: ì´ì „ {len(prev_df_to_merge)}í–‰ + í˜„ì¬ {len(current_df_to_merge)}í–‰ = ì´ {len(merged_df)}í–‰")
        # if prev_col_count != curr_col_count:
        #     logger.debug(f"ë³‘í•©ëœ í…Œì´ë¸”:\n{merged_df.to_string()}")
        return merged_df

    except Exception as e:
        logger.exception(f"í…Œì´ë¸” ë³‘í•© ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return prev_table_df


def reconstruct_text_with_merged_tables(original_text: str, merged_tables: list) -> str:
    """
    ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ê°œë³„ í…Œì´ë¸”ë“¤ì„ ë³‘í•©ëœ í…Œì´ë¸”ë¡œ êµì²´í•˜ë˜, ì™„ë²½í•œ ì›ë³¸ ë¬¸ì„œ êµ¬ì¡°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

    í…Œì´ë¸” ë³‘í•©ìœ¼ë¡œ ì¸í•œ ì¸ë±ìŠ¤ ë³€í™”ë¥¼ ì •í™•íˆ ë§¤í•‘í•˜ì—¬ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— í…Œì´ë¸”ì„ ë°°ì¹˜í•©ë‹ˆë‹¤.

    Args:
        original_text: í˜ì´ì§€ë³„ë¡œ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸
        merged_tables: ë³‘í•©ëœ í…Œì´ë¸” ì •ë³´ ë¦¬ìŠ¤íŠ¸

    Returns:
        str: ë³‘í•©ëœ í…Œì´ë¸”ë¡œ ì¬êµ¬ì„±ëœ í…ìŠ¤íŠ¸ (ì™„ë²½í•œ ì›ë³¸ êµ¬ì¡° ìœ ì§€)
    """
    if not merged_tables:
        return original_text

    # 1. ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ í…Œì´ë¸”ë“¤ì˜ ìœ„ì¹˜ì™€ ìˆœì„œë¥¼ íŒŒì•…
    lines = original_text.split("\n")
    table_positions = []  # [(start_idx, end_idx, original_table_order), ...]
    current_table_start = None
    original_table_order = 0

    for i, line in enumerate(lines):
        is_table_line = line.strip().startswith("|") and "|" in line.strip()[1:]

        if is_table_line and current_table_start is None:
            # í…Œì´ë¸” ì‹œì‘
            current_table_start = i
        elif not is_table_line and current_table_start is not None:
            # í…Œì´ë¸” ë
            table_positions.append((current_table_start, i - 1, original_table_order))
            current_table_start = None
            original_table_order += 1

    # ë§ˆì§€ë§‰ í…Œì´ë¸”ì´ í…ìŠ¤íŠ¸ ëê¹Œì§€ ì´ì–´ì§€ëŠ” ê²½ìš°
    if current_table_start is not None:
        table_positions.append((current_table_start, len(lines) - 1, original_table_order))

    logger.debug(f"ì›ë³¸ í…Œì´ë¸” ìœ„ì¹˜: {len(table_positions)}ê°œ, ë³‘í•©ëœ í…Œì´ë¸”: {len(merged_tables)}ê°œ")

    # 2. ì›ë³¸ í…Œì´ë¸” â†’ ë³‘í•©ëœ í…Œì´ë¸” ë§¤í•‘ í…Œì´ë¸” êµ¬ì¶•
    original_to_merged_mapping = {}  # {ì›ë³¸_í…Œì´ë¸”_ìˆœì„œ: ë³‘í•©ëœ_í…Œì´ë¸”_ì¸ë±ìŠ¤}

    # ë³‘í•©ëœ í…Œì´ë¸”ë“¤ì„ í˜ì´ì§€ ìˆœì„œë¡œ ì •ë ¬
    sorted_merged_tables = sorted(merged_tables, key=lambda x: (min(x.get("merged_from_pages", [x.get("page_num", 999)])), x.get("table_id", 0)))

    # ë§¤í•‘ êµ¬ì¶•: ê° ë³‘í•©ëœ í…Œì´ë¸”ì´ ì›ë³¸ì˜ ëª‡ ë²ˆì§¸ í…Œì´ë¸”ë“¤ì„ ëŒ€ì²´í•˜ëŠ”ì§€ ì¶”ì 
    current_original_index = 0

    for merged_idx, merged_table in enumerate(sorted_merged_tables):
        table_count_in_group = merged_table.get("table_count_in_group", 1)

        # ì´ ë³‘í•©ëœ í…Œì´ë¸”ì´ ëŒ€ì²´í•˜ëŠ” ì›ë³¸ í…Œì´ë¸”ë“¤ì˜ ë²”ìœ„
        for i in range(table_count_in_group):
            if current_original_index < len(table_positions):
                original_to_merged_mapping[current_original_index] = merged_idx
                current_original_index += 1

    logger.debug(f"ë§¤í•‘ ì™„ë£Œ: {original_to_merged_mapping}")

    # 3. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì¬êµ¬ì„± (ë’¤ì—ì„œë¶€í„° êµì²´í•´ì•¼ ì¸ë±ìŠ¤ê°€ ì•ˆ ê¹¨ì§)
    result_lines = lines[:]
    processed_merged_tables = set()  # ì´ë¯¸ ì²˜ë¦¬ëœ ë³‘í•©ëœ í…Œì´ë¸” ì¶”ì 

    # í…Œì´ë¸” ìœ„ì¹˜ë¥¼ ë’¤ì—ì„œë¶€í„° ì²˜ë¦¬ (ì¸ë±ìŠ¤ ë³€í™” ë°©ì§€)
    for start_idx, end_idx, original_table_order in reversed(table_positions):
        if original_table_order in original_to_merged_mapping:
            merged_table_idx = original_to_merged_mapping[original_table_order]

            # ì´ë¯¸ ì²˜ë¦¬ëœ ë³‘í•©ëœ í…Œì´ë¸”ì¸ ê²½ìš° í•´ë‹¹ ì˜ì—­ì„ ì œê±°ë§Œ í•¨
            if merged_table_idx in processed_merged_tables:
                logger.debug(f"ì›ë³¸ í…Œì´ë¸” {original_table_order} ì˜ì—­ ì œê±° (ì´ë¯¸ ë³‘í•©ë¨)")
                # í•´ë‹¹ í…Œì´ë¸” ì˜ì—­ì„ ë¹ˆ ê³µê°„ìœ¼ë¡œ ëŒ€ì²´
                result_lines[start_idx : end_idx + 1] = []
                continue

            # ì²˜ìŒ ë§Œë‚˜ëŠ” ë³‘í•©ëœ í…Œì´ë¸”ì¸ ê²½ìš° ì‹¤ì œ í…Œì´ë¸”ë¡œ êµì²´
            table_info = sorted_merged_tables[merged_table_idx]
            processed_merged_tables.add(merged_table_idx)

            if table_info.get("markdown"):
                # ë³‘í•© ì •ë³´ í‘œì‹œ
                # pages_info = table_info.get("merged_from_pages", [table_info.get("page_num")])
                # table_count_merge = table_info.get("table_count_in_group", 1)

                replacement_lines = []
                # if table_count_merge > 1:
                #     replacement_lines.append(f"### ğŸ“‹ ë³‘í•©ëœ í…Œì´ë¸” (í˜ì´ì§€ {pages_info}ì—ì„œ {table_count_merge}ê°œ ë³‘í•©)")

                # ë³‘í•©ëœ í…Œì´ë¸”ì˜ ë§ˆí¬ë‹¤ìš´ ì¶”ê°€
                markdown_lines = table_info["markdown"].strip().split("\n")
                replacement_lines.extend(markdown_lines)

                # ì›ë³¸ í…Œì´ë¸” ì˜ì—­ì„ ë³‘í•©ëœ í…Œì´ë¸”ë¡œ êµì²´
                result_lines[start_idx : end_idx + 1] = replacement_lines

                # logger.debug(f"ì›ë³¸ í…Œì´ë¸” {original_table_order} â†’ ë³‘í•©ëœ í…Œì´ë¸” {merged_table_idx} êµì²´ ì™„ë£Œ")
        else:
            logger.debug(f"ì›ë³¸ í…Œì´ë¸” {original_table_order}ì— ëŒ€ì‘í•˜ëŠ” ë³‘í•©ëœ í…Œì´ë¸” ì—†ìŒ - ì˜ì—­ ì œê±°")
            # ë§¤í•‘ë˜ì§€ ì•Šì€ ì›ë³¸ í…Œì´ë¸” ì˜ì—­ ì œê±° (ë³‘í•©ë˜ì–´ ì‚¬ë¼ì§„ í…Œì´ë¸”)
            result_lines[start_idx : end_idx + 1] = []

    return "\n".join(result_lines)


def analyze_table_structure_across_pages(all_page_tables: list) -> list:
    """
    ì—¬ëŸ¬ í˜ì´ì§€ì˜ í…Œì´ë¸”ë“¤ì„ ë¶„ì„í•˜ì—¬ ì—°ê²°ëœ í…Œì´ë¸”ë“¤ì„ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.

    Args:
        all_page_tables: ëª¨ë“  í˜ì´ì§€ì˜ í…Œì´ë¸” ì •ë³´ ë¦¬ìŠ¤íŠ¸
                        [{'page_num': int, 'tables': [table_info, ...]}, ...]

    Returns:
        list: ê·¸ë£¹í™”ëœ í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸
              [{'tables': [merged_table_info], 'pages': [page_nums]}, ...]
    """
    if not all_page_tables:
        return []

    grouped_tables = []
    current_group = None

    for page_info in all_page_tables:
        page_num = page_info["page_num"]
        page_tables = page_info["tables"]

        for i, table_info in enumerate(page_tables):
            table_df = table_info.get("dataframe")

            # ì™„ì „íˆ ë¹„ì–´ìˆëŠ” DataFrame(ì»¬ëŸ¼ë„ ì—†ìŒ)ë§Œ ê±´ë„ˆë›°ê³ ,
            # í—¤ë”ë§Œ ìˆëŠ” í…Œì´ë¸”(empty=Trueì´ì§€ë§Œ columns ì¡´ì¬)ì€ ìœ íš¨í•œ í…Œì´ë¸”ë¡œ ì²˜ë¦¬
            if table_df is None or (table_df.empty and table_df.columns.empty):
                logger.debug(f"í˜ì´ì§€ {page_num} í…Œì´ë¸” {i + 1}: ì™„ì „íˆ ë¹„ì–´ìˆëŠ” í…Œì´ë¸”ë¡œ ê±´ë„ˆëœ€")
                continue

            # í—¤ë”ë§Œ ìˆëŠ” í…Œì´ë¸”ì¸ì§€ ë¡œê¹…
            if table_df.empty and not table_df.columns.empty:
                logger.debug(f"í˜ì´ì§€ {page_num} í…Œì´ë¸” {i + 1}: í—¤ë”ë§Œ ìˆëŠ” í…Œì´ë¸”ë¡œ ì—°ì†ì„± íŒë‹¨ì— í¬í•¨ (ì»¬ëŸ¼: {list(table_df.columns)})")

            # ì²« ë²ˆì§¸ í…Œì´ë¸”ì´ê±°ë‚˜ ì´ì „ ê·¸ë£¹ì´ ì—†ìœ¼ë©´ ìƒˆ ê·¸ë£¹ ì‹œì‘
            if current_group is None:
                current_group = {"merged_table": table_info, "pages": [page_num], "table_count": 1}
                # logger.debug(f"ìƒˆë¡œìš´ í…Œì´ë¸” ê·¸ë£¹ ì‹œì‘: í˜ì´ì§€ {page_num} í…Œì´ë¸” {i + 1}")
                continue

            # 1ì°¨: ì¢Œí‘œ ê¸°ë°˜ ì—°ì†ì„± íŒë‹¨ (ìš°ì„ ìˆœìœ„)
            prev_table_info = current_group["merged_table"]
            should_merge = False
            merge_reason = ""

            if is_position_based_continuation(prev_table_info, table_info):
                should_merge = True
                merge_reason = "ì¢Œí‘œ ê¸°ë°˜ ì—°ì†ì„±"
                # logger.debug(f"í…Œì´ë¸” ì—°ê²° íŒë‹¨[{page_num}]: {merge_reason} ê°ì§€")

                # ğŸ“‹ í•µì‹¬ ê°œì„ : í˜ì´ì§€ ê°„ ì—°ì†ì„±ì´ í™•ì¸ë˜ë©´ í˜„ì¬ í…Œì´ë¸”ì˜ í—¤ë”ë¥¼ ì²« í–‰ìœ¼ë¡œ ë³µêµ¬
                current_df = table_df.copy()
                if len(current_df.columns) > 0:  # ğŸ“‹ ê°œì„ : í—¤ë”ë§Œ ìˆëŠ” í…Œì´ë¸”ë„ ì²˜ë¦¬ ê°€ëŠ¥
                    # í—¤ë” ì¶”ê°€ ì „ì— ì›ë³¸ í…Œì´ë¸” ìƒíƒœ í™•ì¸
                    was_header_only = current_df.empty

                    # í˜„ì¬ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ëª…ì„ ì²« í–‰ìœ¼ë¡œ ì‚½ì…
                    header_row = pd.DataFrame([current_df.columns], columns=current_df.columns)
                    current_df = pd.concat([header_row, current_df], ignore_index=True)

                    # if was_header_only:
                    #     logger.debug("í˜ì´ì§€ ê°„ ì—°ì†ì„± í™•ì¸: í—¤ë”ë§Œ ìˆëŠ” í…Œì´ë¸”ì˜ í—¤ë”ë¥¼ ì²« í–‰ìœ¼ë¡œ ë³µêµ¬ ì™„ë£Œ")
                    # else:
                    #     logger.debug("í˜ì´ì§€ ê°„ ì—°ì†ì„± í™•ì¸: í˜„ì¬ í…Œì´ë¸”ì˜ í—¤ë”ë¥¼ ì²« í–‰ìœ¼ë¡œ ë³µêµ¬ ì™„ë£Œ")

                # ë³µêµ¬ëœ DataFrameìœ¼ë¡œ í…Œì´ë¸” ì •ë³´ ì—…ë°ì´íŠ¸
                table_info["dataframe"] = current_df
                table_df = current_df

            if should_merge:
                # í…Œì´ë¸” ë³‘í•©
                prev_table_df = current_group["merged_table"].get("dataframe")
                merged_df = merge_continued_tables(prev_table_df, table_df)

                # ê·¸ë£¹ ì •ë³´ ì—…ë°ì´íŠ¸
                current_group["merged_table"]["dataframe"] = merged_df
                current_group["merged_table"]["original_dataframe"] = merged_df  # ì›ë³¸ë„ ì—…ë°ì´íŠ¸
                current_group["pages"].append(page_num)
                current_group["table_count"] += 1

                # ë§ˆí¬ë‹¤ìš´ì€ ë‚˜ì¤‘ì— ë‹¨ìœ„ ë³€í™˜ í›„ ìƒì„±
                # logger.debug(f"âœ… í…Œì´ë¸” ë³‘í•© ì„±ê³µ: í˜ì´ì§€ {page_num} í…Œì´ë¸” {i + 1} ({merge_reason}, ì´ {len(merged_df)}í–‰)")

            else:
                # ì´ì „ ê·¸ë£¹ì„ ì™„ë£Œí•˜ê³  ìƒˆ ê·¸ë£¹ ì‹œì‘
                grouped_tables.append(current_group)
                current_group = {"merged_table": table_info, "pages": [page_num], "table_count": 1}
                # logger.debug(f"ìƒˆë¡œìš´ í…Œì´ë¸” ê·¸ë£¹ ì‹œì‘: í˜ì´ì§€ {page_num} í…Œì´ë¸” {i + 1}")

    # ë§ˆì§€ë§‰ ê·¸ë£¹ ì¶”ê°€
    if current_group is not None:
        grouped_tables.append(current_group)

    logger.info(f"í…Œì´ë¸” ê·¸ë£¹í™” ì™„ë£Œ: ì´ {len(grouped_tables)}ê°œ ê·¸ë£¹, í˜ì´ì§€ ë²”ìœ„: {all_page_tables[0]['page_num']}~{all_page_tables[-1]['page_num']}")

    # ê²°ê³¼ í¬ë§·íŒ… ë° ë‹¨ìœ„ ë³€í™˜ ìˆ˜í–‰
    result = []
    for i, group in enumerate(grouped_tables):
        group_info = group["merged_table"].copy()
        group_info["merged_from_pages"] = group["pages"]
        group_info["table_count_in_group"] = group["table_count"]
        group_info["table_id"] = i + 1  # ìƒˆë¡œìš´ í…Œì´ë¸” ID í• ë‹¹

        # ë³‘í•©ëœ í…Œì´ë¸”ì— ëŒ€í•´ ë‹¨ìœ„ ë³€í™˜ ìˆ˜í–‰
        merged_df = group_info.get("dataframe")
        unit_info = group_info.get("unit_info", "")

        if merged_df is not None and not merged_df.empty and unit_info:
            try:
                source_unit_clean = unit_info.replace("ë‹¨ìœ„:", "").replace("ë‹¨ìœ„ :", "").strip().lower()
                target_unit = None

                # íƒ€ê²Ÿ ë‹¨ìœ„ ê²°ì • ë¡œì§ (êµ¬ì²´ì ì¸ ë‹¨ìœ„ë¶€í„° ë¨¼ì € ì²´í¬)
                if "ì¡°ì›" in source_unit_clean:
                    target_unit = None  # ì´ë¯¸ ìµœëŒ€ ë‹¨ìœ„ì´ë¯€ë¡œ ë³€í™˜í•˜ì§€ ì•ŠìŒ
                elif "ì‹­ì–µì›" in source_unit_clean:
                    # ì‹­ì–µì›ì¼ ë•Œë„ max ê°’ì´ 100 ì´ìƒì´ë©´ ì¡°ì›ìœ¼ë¡œ ë³€í™˜
                    max_abs_val = get_max_abs_value_from_dataframe(merged_df)
                    if max_abs_val >= 100:
                        target_unit = "ì¡°ì›"
                    else:
                        target_unit = None  # ë³€í™˜í•˜ì§€ ì•ŠìŒ
                elif "ì–µì›" in source_unit_clean:
                    # ë‹¨ìˆœ "ì–µì›"ì¸ ê²½ìš°ë§Œ ì²˜ë¦¬
                    max_abs_val = get_max_abs_value_from_dataframe(merged_df)
                    if max_abs_val >= 1000:
                        target_unit = "ì¡°ì›"
                    else:
                        target_unit = "ì‹­ì–µì›"
                elif "ë°±ë§Œì›" in source_unit_clean:
                    target_unit = "ì‹­ì–µì›"  # ë°±ë§Œì› -> ì‹­ì–µì›
                elif "ì²œì›" in source_unit_clean:
                    target_unit = "ì‹­ì–µì›"  # ì²œì› -> ì‹­ì–µì›
                elif "ì›" in source_unit_clean and "ì–µ" not in source_unit_clean:
                    max_abs_val = get_max_abs_value_from_dataframe(merged_df)
                    if max_abs_val < 100000000:  # 1ì–µ ë¯¸ë§Œì´ë©´, ë°±ë§Œì› ë‹¨ìœ„.
                        target_unit = "ë°±ë§Œì›"
                    else:
                        target_unit = "ì‹­ì–µì›"  # ì› -> ì‹­ì–µì›

                # ë‹¨ìœ„ ë³€í™˜ ì‹¤í–‰
                if target_unit and target_unit not in source_unit_clean:
                    converted_df = convert_dataframe_units(merged_df, unit_info, target_unit)
                    if converted_df is not None and not converted_df.empty:
                        group_info["dataframe"] = converted_df
                        group_info["converted_unit"] = converted_df.attrs.get("converted_unit")
                        # logger.debug(f"ë³‘í•©ëœ í…Œì´ë¸” {i + 1} ë‹¨ìœ„ ë³€í™˜: {unit_info} -> {group_info['converted_unit']}")
                else:
                    logger.debug(f"ë³‘í•©ëœ í…Œì´ë¸” {i + 1} ë‹¨ìœ„ ë³€í™˜ ê±´ë„ˆëœ€: íƒ€ê²Ÿ ë‹¨ìœ„({target_unit})ê°€ ì†ŒìŠ¤ì™€ ë™ì¼í•˜ê±°ë‚˜ ì—†ìŒ")

            except Exception as convert_error:
                logger.warning(f"ë³‘í•©ëœ í…Œì´ë¸” {i + 1} ë‹¨ìœ„ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {str(convert_error)}")

        # ìµœì¢… DataFrameìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ ìƒì„±
        final_df = group_info.get("dataframe")
        if final_df is not None and not final_df.empty:
            group_info["markdown"] = dataframe_to_markdown(final_df, i + 1, "ìµœì¢…ë°ì´í„°")

        result.append(group_info)

    return result


async def extract_page_gemini_style_with_dataframe(page, page_num: int):
    """
    Gemini ë°©ì‹ìœ¼ë¡œ ë‹¨ì¼ í˜ì´ì§€ì—ì„œ í…Œì´ë¸”ê³¼ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        page: pdfplumber page ê°ì²´
        page_num: í˜ì´ì§€ ë²ˆí˜¸

    Returns:
        dict: {
            'text': str,  # ì¶”ì¶œëœ í…ìŠ¤íŠ¸
            'tables': [   # ì¶”ì¶œëœ í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸
                {
                    'table_id': int,
                    'page_num': int,
                    'dataframe': pd.DataFrame,
                    'unit_info': str,
                    'markdown': str,
                    'raw_data': list
                }
            ]
        }
    """
    try:
        result = {"text": "", "tables": []}

        page_content = ""

        # 1. í˜ì´ì§€ì— ìˆëŠ” í…Œì´ë¸”ë“¤ì˜ ìœ„ì¹˜ ì •ë³´ ì°¾ê¸°
        tables = page.find_tables()

        if not tables:
            # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
            text = page.extract_text()
            if text:
                page_content += text
            result["text"] = page_content
            return result

        # logger.debug(f"í˜ì´ì§€ {page_num}ì—ì„œ {len(tables)} ê°œì˜ í…Œì´ë¸”ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤ (DataFrame ë°©ì‹).")

        # 2. í…Œì´ë¸”ë“¤ì„ Y ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_tables = sorted(tables, key=lambda t: t.bbox[1])  # Y ì¢Œí‘œ(ìƒë‹¨) ê¸°ì¤€ ì •ë ¬

        current_y = 0  # í˜ì´ì§€ ìƒë‹¨ë¶€í„° ì‹œì‘

        for i, table in enumerate(sorted_tables):
            table_bbox = table.bbox  # (x0, top, x1, bottom)

            # 3. í…Œì´ë¸” 'ìœ„ìª½' ì˜ì—­ì„ ì˜ë¼ë‚´ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¨ìœ„ ì •ë³´ í¬í•¨)
            unit_info = ""
            text_above_table_content = ""  # í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì„ì‹œ ì €ì¥í•  ë³€ìˆ˜
            if table_bbox[1] > current_y:  # í…Œì´ë¸” ìƒë‹¨ì´ í˜„ì¬ Y ìœ„ì¹˜ë³´ë‹¤ ì•„ë˜ì— ìˆìœ¼ë©´
                try:
                    top_part_bbox = (0, current_y, page.width, table_bbox[1])
                    text_above_table = page.crop(top_part_bbox).extract_text()
                    if text_above_table and text_above_table.strip():
                        # ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ
                        unit_info = extract_unit_info(text_above_table)
                        # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ìœ„ ì •ë³´ ì œê±°
                        text_above_table_content = remove_unit_from_text(text_above_table)
                except Exception as crop_error:
                    logger.debug(f"í…Œì´ë¸” {i + 1} ìœ„ìª½ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {str(crop_error)}")

            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ í˜ì´ì§€ ì½˜í…ì¸ ì— ì¶”ê°€ (ë‹¨ìœ„ ì •ë³´ê°€ ì œê±°ëœ í…ìŠ¤íŠ¸)
            if text_above_table_content:
                page_content += text_above_table_content + "\n\n"

            # 4. í…Œì´ë¸” ì˜ì—­ì„ ì˜ë¼ë‚´ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ì¶”ì¶œ
            try:
                # Gemini ë°©ì‹ì˜ í•µì‹¬: ëª…ì‹œì ì¸ í…Œì´ë¸” ì¶”ì¶œ ì „ëµ ì‚¬ìš©
                table_settings = {
                    "vertical_strategy": "lines",
                    "horizontal_strategy": "lines",
                    "snap_tolerance": 3,
                    "join_tolerance": 3,
                    "edge_min_length": 3,
                    "min_words_vertical": 1,
                    "min_words_horizontal": 1,
                }

                structured_table = page.crop(table_bbox).extract_table(table_settings)

                if structured_table and len(structured_table) > 0:
                    # ë‹¨ìœ„ ì •ë³´ê°€ í…Œì´ë¸” ìœ„ì—ì„œ ì°¾ì•„ì§€ì§€ ì•Šì•˜ì„ ê²½ìš°, í…Œì´ë¸” ë‚´ë¶€ì—ì„œ ë‹¤ì‹œ ê²€ìƒ‰
                    if not unit_info:
                        # í…Œì´ë¸”ì˜ ì²«ë²ˆì§¸ í–‰ì„ ìˆœíšŒí•˜ë©° ë‹¨ìœ„ ì •ë³´ íƒìƒ‰
                        for cell_content in structured_table[0]:
                            if cell_content:
                                new_unit_info = extract_unit_info(str(cell_content))
                                if new_unit_info:
                                    unit_info = new_unit_info
                                    # logger.debug(f"í…Œì´ë¸” {i + 1} ë‚´ë¶€ì—ì„œ ë‹¨ìœ„ ì •ë³´ ë°œê²¬: '{unit_info}'. í•´ë‹¹ í–‰ì„ í…Œì´ë¸”ì—ì„œ ì œê±°í•©ë‹ˆë‹¤.")
                                    # ë‹¨ìœ„ ì •ë³´ë¥¼ í¬í•¨í•œ í–‰ì€ ì‹¤ì œ ë°ì´í„°ê°€ ì•„ë‹ˆë¯€ë¡œ ì œê±°
                                    structured_table = structured_table[1:]
                                    break  # ë‹¨ìœ„ ì •ë³´ë¥¼ ì°¾ì•˜ìœ¼ë©´ ë°˜ë³µ ì¤‘ë‹¨

                    # ë²”ìš©ì  í—¤ë” ì²˜ë¦¬: ëª¨ë“  í…Œì´ë¸”ì„ í—¤ë”ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ê°€ì •
                    # í˜ì´ì§€ ê°„ ì—°ì†ì„± íŒë‹¨ì€ analyze_table_structure_across_pages()ì—ì„œ ì²˜ë¦¬

                    # DataFrame ìƒì„±
                    df = create_dataframe_from_table(structured_table, unit_info)

                    # if text_above_table_content:
                    #     page_content += f"{text_above_table_content}\n"

                    # DataFrameì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (ì›ë³¸ ë°ì´í„°ë¡œ)
                    if df is not None and not df.empty:
                        markdown_content = dataframe_to_markdown(df, i + 1, "ì›ë³¸ë°ì´í„°")
                    else:
                        # DataFrameì´ ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ ë°©ì‹ìœ¼ë¡œ í´ë°±
                        markdown_content = ""
                        for row_idx, row in enumerate(structured_table):
                            if row and any(cell for cell in row if cell):
                                cleaned_row = []
                                for cell in row:
                                    if cell:
                                        clean_cell = str(cell).strip().replace("\n", " ").replace("\r", "")
                                        clean_cell = " ".join(clean_cell.split())
                                        cleaned_row.append(clean_cell)
                                    else:
                                        cleaned_row.append("")

                                markdown_content += "| " + " | ".join(cleaned_row) + " |\n"

                                # í—¤ë” í–‰ ë‹¤ìŒì— êµ¬ë¶„ì„  ì¶”ê°€
                                if row_idx == 0 and len(structured_table) > 1:
                                    separator = ["---"] * len(cleaned_row)
                                    markdown_content += "| " + " | ".join(separator) + " |\n"
                        markdown_content += "\n"

                    page_content += markdown_content

                    # í…Œì´ë¸” ì •ë³´ ì €ì¥ (ì›ë³¸ DataFrameë§Œ ì €ì¥, ë‹¨ìœ„ ë³€í™˜ì€ ë‚˜ì¤‘ì—)
                    table_info = {
                        "table_id": i + 1,
                        "page_num": page_num,
                        "dataframe": df,  # ì›ë³¸ DataFrame ì €ì¥
                        "original_dataframe": df,  # ì›ë³¸ DataFrameë„ ì €ì¥
                        "unit_info": unit_info,
                        "converted_unit": "",  # ë³€í™˜ ì „ì´ë¯€ë¡œ ë¹ˆ ê°’
                        "markdown": markdown_content,
                        "raw_data": structured_table,
                        "bbox": table_bbox,  # ì¢Œí‘œ ì •ë³´ ì¶”ê°€
                        "table_position_in_page": i,  # í˜ì´ì§€ ë‚´ í…Œì´ë¸” ìˆœì„œ
                        "page_height": page.height,  # ì‹¤ì œ í˜ì´ì§€ ë†’ì´ ì¶”ê°€
                    }

                    result["tables"].append(table_info)

                    # logger.debug(f"í…Œì´ë¸” {i + 1} DataFrame ì²˜ë¦¬ ì™„ë£Œ: {df.shape if df is not None else 'None'}, ë‹¨ìœ„: {unit_info} (ë³€í™˜ ì „)")
                else:
                    raise Exception("êµ¬ì¡°í™”ëœ í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨")

            except Exception as table_error:
                logger.debug(f"í…Œì´ë¸” {i + 1} êµ¬ì¡°í™” ì¶”ì¶œ ì˜¤ë¥˜ (DataFrame ë°©ì‹): {str(table_error)}")
                # í´ë°±: í…Œì´ë¸” ì˜ì—­ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
                try:
                    table_text = page.crop(table_bbox).extract_text()
                    if table_text and table_text.strip():
                        page_content += f"[í…Œì´ë¸” {i + 1} - í…ìŠ¤íŠ¸ í˜•íƒœ]\n{table_text.strip()}\n\n"
                        logger.debug(f"í…Œì´ë¸” {i + 1} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ (í´ë°±): {len(table_text)} ê¸€ì")
                except Exception as fallback_error:
                    logger.error(f"í…Œì´ë¸” {i + 1} ëª¨ë“  ì¶”ì¶œ ë°©ë²• ì‹¤íŒ¨: {str(fallback_error)}")

            # í˜„ì¬ Y ìœ„ì¹˜ë¥¼ í…Œì´ë¸” í•˜ë‹¨ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            current_y = table_bbox[3]

        # 5. ë§ˆì§€ë§‰ í…Œì´ë¸” 'ì•„ë˜ìª½' ì˜ì—­ì„ ì˜ë¼ë‚´ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if current_y < page.height:
            try:
                bottom_part_bbox = (0, current_y, page.width, page.height)
                text_below_table = page.crop(bottom_part_bbox).extract_text()
                if text_below_table and text_below_table.strip():
                    page_content += f"{text_below_table.strip()}\n"
            except Exception as crop_error:
                logger.debug(f"ë§ˆì§€ë§‰ í…Œì´ë¸” ì•„ë˜ìª½ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {str(crop_error)}")

        cleaned_page_content = _clean_extracted_text(page_content)
        result["text"] = cleaned_page_content
        return result

    except Exception as e:
        logger.error(f"í˜ì´ì§€ {page_num} DataFrame ë°©ì‹ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        # ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œë¡œ í´ë°±
        try:
            fallback_text = page.extract_text()
            cleaned_fallback_text = _clean_extracted_text(fallback_text)
            return {"text": f"[í´ë°± í…ìŠ¤íŠ¸]\n{cleaned_fallback_text}\n" if cleaned_fallback_text else "", "tables": []}
        except Exception as fallback_error:
            logger.error(f"í˜ì´ì§€ {page_num} í´ë°± í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {str(fallback_error)}")
            return {"text": "", "tables": []}
