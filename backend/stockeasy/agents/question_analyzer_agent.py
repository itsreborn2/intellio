"""
ì§ˆë¬¸ ë¶„ì„ê¸° ì—ì´ì „íŠ¸ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì˜ë„, ì—”í‹°í‹°, í‚¤ì›Œë“œ ë“±ì˜ 
ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” QuestionAnalyzerAgent í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import json
from loguru import logger
from typing import Dict, List, Any, Optional, Literal, cast, Union
from datetime import datetime
import os
import asyncio

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field
from typing import List, Optional as PydanticOptional
from stockeasy.services.financial.stock_info_service import StockInfoService
from common.models.token_usage import ProjectType
from common.services.agent_llm import get_llm_for_agent, get_agent_llm
from stockeasy.prompts.question_analyzer_prompts import PROMPT_DYNAMIC_TOC, SYSTEM_PROMPT, format_question_analyzer_prompt
from common.core.config import settings
from common.core.redis import AsyncRedisClient
from stockeasy.models.agent_io import (
    QuestionAnalysisResult, ExtractedEntity, QuestionClassification, 
    DataRequirement, pydantic_to_typeddict
)
from langchain_core.prompts import ChatPromptTemplate
from stockeasy.agents.base import BaseAgent
from sqlalchemy.ext.asyncio import AsyncSession
#from langchain_tavily import TavilySearch
from common.services.tavily import TavilyService

class Entities(BaseModel):
    """ì¶”ì¶œëœ ì—”í‹°í‹° ì •ë³´"""
    stock_name: PydanticOptional[str] = Field(None, description="ì¢…ëª©ëª… ë˜ëŠ” null")
    stock_code: PydanticOptional[str] = Field(None, description="ì¢…ëª©ì½”ë“œ ë˜ëŠ” null")
    sector: PydanticOptional[str] = Field(None, description="ì¢…ëª©ì´ ì†í•œ ì‚°ì—…/ì„¹í„° ë˜ëŠ” null")
    subgroup: PydanticOptional[list] = Field(None, description="ì¢…ëª©ì´ ì†í•œ subgroup ë˜ëŠ” null")
    time_range: PydanticOptional[str] = Field(None, description="ì‹œê°„ë²”ìœ„ ë˜ëŠ” null")
    financial_metric: PydanticOptional[str] = Field(None, description="ì¬ë¬´ì§€í‘œ ë˜ëŠ” null")
    competitor: PydanticOptional[str] = Field(None, description="ê²½ìŸì‚¬ ë˜ëŠ” null")
    product: PydanticOptional[str] = Field(None, description="ì œí’ˆ/ì„œë¹„ìŠ¤ ë˜ëŠ” null")



class Classification(BaseModel):
    """ì§ˆë¬¸ ë¶„ë¥˜ ì •ë³´"""
    primary_intent: Literal["ì¢…ëª©ê¸°ë³¸ì •ë³´", "ì„±ê³¼ì „ë§", "ì¬ë¬´ë¶„ì„", "ì‚°ì—…ë™í–¥", "ê¸°íƒ€"] = Field(
        ..., 
        description=(
            "ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤: "
            "'ì¢…ëª©ê¸°ë³¸ì •ë³´'(íšŒì‚¬ ê°œìš”, í˜„ì¬ ì£¼ê°€ ë“± ë‹¨ìˆœ ì •ë³´), "
            "'ì„±ê³¼ì „ë§'(ë¯¸ë˜ ì‹¤ì  ì˜ˆì¸¡, ëª©í‘œ ì£¼ê°€ ë“± ì˜ˆì¸¡/ì „ë§), "
            "'ì¬ë¬´ë¶„ì„'(ì¬ë¬´ì œí‘œ ìˆ˜ì¹˜, ë¹„ìœ¨ ë¶„ì„ ë“± ìƒì„¸ ë¶„ì„), "
            "'ì‚°ì—…ë™í–¥'(ê´€ë ¨ ì‚°ì—…/ì‹œì¥ ë¶„ì„, ê²½ìŸì‚¬ ë¹„êµ ë“±), "
            "'ê¸°íƒ€'(ìœ„ ë²”ì£¼ì— ì†í•˜ì§€ ì•Šê±°ë‚˜ ë¶„ë¥˜í•˜ê¸° ì–´ë ¤ìš´ ê²½ìš°). "
            "ì§ˆë¬¸ì˜ ì˜ë„ê°€ ëª¨í˜¸í•˜ë‹¤ë©´ ê°€ì¥ ì ì ˆí•˜ë‹¤ê³  íŒë‹¨ë˜ëŠ” í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê±°ë‚˜ 'ê¸°íƒ€'ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”."
        )
    )
    complexity: Literal["ë‹¨ìˆœ", "ì¤‘ê°„", "ë³µí•©", "ì „ë¬¸ê°€ê¸‰"] = Field(
        ..., 
        description=(
            "ì§ˆë¬¸ì˜ ë³µì¡ë„ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤: "
            "'ë‹¨ìˆœ'(ë‹¨ì¼ ì •ë³´ ìš”ì²­, ì˜ˆ: 'í˜„ì¬ ì£¼ê°€ ì–¼ë§ˆì•¼?'), "
            "'ì¤‘ê°„'(ì—¬ëŸ¬ ì •ë³´ ê²°í•© ë˜ëŠ” ê°„ë‹¨í•œ ë¶„ì„ ìš”êµ¬, ì˜ˆ: 'ìµœê·¼ 1ë…„ ì£¼ê°€ ì¶”ì´ì™€ ì£¼ìš” ì´ìŠˆ ì•Œë ¤ì¤˜'), "
            "'ë³µí•©'(ë‹¤ê°ì  ë¶„ì„, ë¹„êµ, ê¹Šì€ ì´í•´ ìš”êµ¬, ì˜ˆ: 'ê²½ìŸì‚¬ ëŒ€ë¹„ ì¬ë¬´ ê±´ì „ì„±ê³¼ ì„±ì¥ ì „ë§ ë¶„ì„í•´ì¤˜'), "
            "'ì „ë¬¸ê°€ê¸‰'(ë§¤ìš° ì‹¬ì¸µì ì¸ ë¶„ì„, íŠ¹ì • ëª¨ë¸ë§/ê°€ì • ìš”êµ¬, ì˜ˆ: 'DCF ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ í–¥í›„ 5ë…„ ì˜ˆìƒ ì£¼ê°€ ì‚°ì¶œí•´ì¤˜'). "
            "ì§ˆë¬¸ì˜ ìš”êµ¬ì‚¬í•­ê³¼ ë¶„ì„ ê¹Šì´ë¥¼ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì í•©í•œ ìˆ˜ì¤€ì„ ì„ íƒí•˜ì„¸ìš”."
        )
    )
    expected_answer_type: Literal["ì‚¬ì‹¤í˜•", "ì¶”ë¡ í˜•", "ë¹„êµí˜•", "ì˜ˆì¸¡í˜•", "ì„¤ëª…í˜•", "ì¢…í•©í˜•"] = Field(
        ..., 
        description=(
            "ì‚¬ìš©ìê°€ ê¸°ëŒ€í•˜ëŠ” ë‹µë³€ì˜ ìœ í˜•ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤: "
            "'ì‚¬ì‹¤í˜•'(ê°ê´€ì ì¸ ë°ì´í„°ë‚˜ ì •ë³´ ì „ë‹¬, ì˜ˆ: 'ì‘ë…„ ë§¤ì¶œì•¡ì€?'), "
            "'ì¶”ë¡ í˜•'(ì£¼ì–´ì§„ ì •ë³´ ê¸°ë°˜ì˜ ë…¼ë¦¬ì  ì¶”ë¡ /í•´ì„, ì˜ˆ: 'ìµœê·¼ ì‹¤ì  ë°œí‘œê°€ ì£¼ê°€ì— ë¯¸ì¹  ì˜í–¥ì€?'), "
            "'ë¹„êµí˜•'(ë‘˜ ì´ìƒì˜ ëŒ€ìƒì„ ë¹„êµ ë¶„ì„, ì˜ˆ: 'Aì‚¬ì™€ Bì‚¬ì˜ ìˆ˜ìµì„± ë¹„êµ'), "
            "'ì˜ˆì¸¡í˜•'(ë¯¸ë˜ ìƒíƒœë‚˜ ê²°ê³¼ ì˜ˆì¸¡, ì˜ˆ: 'ë‹¤ìŒ ë¶„ê¸° ì‹¤ì  ì „ë§ì€?'), "
            "'ì„¤ëª…í˜•'(ê°œë…, ì›ì¸, ê³¼ì • ë“±ì— ëŒ€í•œ ì„¤ëª…, ì˜ˆ: 'PERì´ ë¬´ì—‡ì¸ê°€ìš”?'), "
            "'ì¢…í•©í˜•'(ì—¬ëŸ¬ ìœ í˜•ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì œê³µ). "
            "ì§ˆë¬¸ì˜ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì— ë§ì¶° ê°€ì¥ ì í•©í•œ ë‹µë³€ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”."
        )
    )


class DataRequirements(BaseModel):
    """ë°ì´í„° ìš”êµ¬ì‚¬í•­"""
    telegram_needed: bool = Field(..., description="í…”ë ˆê·¸ë¨ ë°ì´í„° í•„ìš” ì—¬ë¶€")
    reports_needed: bool = Field(..., description="ë¦¬í¬íŠ¸ ë°ì´í„° í•„ìš” ì—¬ë¶€")
    financial_statements_needed: bool = Field(..., description="ì¬ë¬´ì œí‘œ ë°ì´í„° í•„ìš” ì—¬ë¶€")
    industry_data_needed: bool = Field(..., description="ì‚°ì—… ë°ì´í„° í•„ìš” ì—¬ë¶€")
    confidential_data_needed: bool = Field(..., description="ë¹„ê³µê°œ ìë£Œ í•„ìš” ì—¬ë¶€")
    revenue_data_needed: bool = Field(False, description="ë§¤ì¶œ ë° ìˆ˜ì£¼ í˜„í™© ë°ì´í„° í•„ìš” ì—¬ë¶€")
    web_search_needed: bool = Field(False, description="ì›¹ ê²€ìƒ‰ ë°ì´í„° í•„ìš” ì—¬ë¶€,ê¸°ë³¸False")

class QuestionAnalysis(BaseModel):
    """ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼"""
    entities: Entities = Field(..., description="ì¶”ì¶œëœ ì—”í‹°í‹° ì •ë³´")
    classification: Classification = Field(..., description="ì§ˆë¬¸ ë¶„ë¥˜ ì •ë³´")
    data_requirements: DataRequirements = Field(..., description="í•„ìš”í•œ ë°ì´í„° ì†ŒìŠ¤ ì •ë³´")
    keywords: List[str] = Field(..., description="ì¤‘ìš” í‚¤ì›Œë“œ ëª©ë¡")
    detail_level: Literal["ê°„ëµ", "ë³´í†µ", "ìƒì„¸"] = Field(..., description="ìš”êµ¬ë˜ëŠ” ìƒì„¸ë„")


class ConversationContextAnalysis(BaseModel):
    """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼"""
    requires_context: bool = Field(..., description="ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ê°€ í•„ìš”í•œì§€ ì—¬ë¶€")
    is_followup_question: bool = Field(..., description="ì´ì „ ì§ˆë¬¸ì— ëŒ€í•œ í›„ì† ì§ˆë¬¸ì¸ì§€ ì—¬ë¶€")
    referenced_context: PydanticOptional[str] = Field(None, description="ì°¸ì¡°í•˜ëŠ” ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ (ìˆëŠ” ê²½ìš°)")
    relation_to_previous: Literal["ë…ë¦½ì ", "ì§ì ‘ì°¸ì¡°", "ê°„ì ‘ì°¸ì¡°", "í™•ì¥", "ìˆ˜ì •"] = Field(..., description="ì´ì „ ëŒ€í™”ì™€ì˜ ê´€ê³„")
    is_conversation_closing: bool = Field(False, description="ëŒ€í™” ë§ˆë¬´ë¦¬ë¥¼ ëœ»í•˜ëŠ” ì¸ì‚¬ë§ì¸ì§€ ì—¬ë¶€")
    closing_type: PydanticOptional[Literal["ê¸ì •ì ", "ì¤‘ë¦½ì ", "ë¶€ì •ì "]] = Field(None, description="ë§ˆë¬´ë¦¬ ì¸ì‚¬ ìœ í˜•")
    closing_response: PydanticOptional[str] = Field(None, description="ë§ˆë¬´ë¦¬ ì¸ì‚¬ì— ëŒ€í•œ ì‘ë‹µ ë©”ì‹œì§€")
    reasoning: str = Field(..., description="íŒë‹¨ì— ëŒ€í•œ ì´ìœ  ì„¤ëª…")
    is_different_stock: bool = Field(False, description="ì´ì „ ì§ˆë¬¸ê³¼ ë‹¤ë¥¸ ì¢…ëª©ì— ê´€í•œ ì§ˆë¬¸ì¸ì§€ ì—¬ë¶€")
    previous_stock_name: PydanticOptional[str] = Field(None, description="ì´ì „ ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ì¢…ëª©ëª…")
    previous_stock_code: PydanticOptional[str] = Field(None, description="ì´ì „ ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ì¢…ëª©ì½”ë“œ")
    stock_relation: PydanticOptional[Literal["ë™ì¼ì¢…ëª©", "ì¢…ëª©ë¹„êµ", "ë‹¤ë¥¸ì¢…ëª©", "ì•Œìˆ˜ì—†ìŒ"]] = Field(None, description="ì´ì „ ì¢…ëª©ê³¼ì˜ ê´€ê³„")


# ìƒˆë¡œìš´ ëª¨ë¸ í´ë˜ìŠ¤ ì¶”ê°€
class DynamicTocOutput(BaseModel):
    """
    ë™ì  ëª©ì°¨ ìƒì„± ê²°ê³¼ë¥¼ ìœ„í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ í¬ë§·
    """
    title: str = Field(
        description="ë³´ê³ ì„œ ì œëª© (ì§ˆë¬¸ê³¼ ê¸°ì—…ëª…ì„ ë°˜ì˜)"
    )
    sections: List[Dict[str, Any]] = Field(
        description="ë³´ê³ ì„œ ì„¹ì…˜ ì •ë³´"
    )

class QuestionAnalyzerAgent(BaseAgent):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸
    
    ì´ ì—ì´ì „íŠ¸ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    1. ì¢…ëª©ì½”ë“œ/ì¢…ëª©ëª… ë“± ì—”í‹°í‹° ì¶”ì¶œ
    2. ì§ˆë¬¸ì˜ ì˜ë„ ë¶„ë¥˜
    3. í•„ìš”í•œ ë°ì´í„° ìœ í˜• ì‹ë³„
    4. í‚¤ì›Œë“œ ì¶”ì¶œ
    """
    
    def __init__(self, name: Optional[str] = None, db: Optional[AsyncSession] = None):
        """
        ì§ˆë¬¸ ë¶„ì„ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        
        Args:
            name: ì—ì´ì „íŠ¸ ì´ë¦„ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ í´ë˜ìŠ¤ëª… ì‚¬ìš©)
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ê°ì²´ (ì„ íƒì )
        """
        super().__init__(name, db)
        self.llm, self.model_name, self.provider = get_llm_for_agent("question_analyzer_agent")
        self.agent_llm = get_agent_llm("question_analyzer_agent")
        self.agent_llm_lite = get_agent_llm("gemini-2.0-flash-lite")
        logger.info(f"QuestionAnalyzerAgent initialized with provider: {self.agent_llm.get_provider()}, model: {self.agent_llm.get_model_name()}")
        self.prompt_template = SYSTEM_PROMPT

        #self.tavily_search = TavilySearch(api_key=settings.TAVILY_API_KEY)
        self.tavily_service = TavilyService()
        self.redis_client = AsyncRedisClient()
    
        
    async def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¤‘ìš” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        Args:
            state: í˜„ì¬ ìƒíƒœ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ì—…ë°ì´íŠ¸ëœ ìƒíƒœ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
            start_time = datetime.now()
            logger.info(f"QuestionAnalyzerAgent starting processing")
            
            # í˜„ì¬ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ
            query = state.get("query", "")
            stock_code = state.get("stock_code", "")
            stock_name = state.get("stock_name", "")
            logger.info(f"query[{stock_name},{stock_code}] : {query}")
            if not query:
                logger.warning("Empty query provided to QuestionAnalyzerAgent")
                self._add_error(state, "ì§ˆë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
                return state

            #state["agent_results"] = state.get("agent_results", {})
            # user_id ì¶”ì¶œ
            user_context = state.get("user_context", {})
            user_id = user_context.get("user_id", None)

            # ëŒ€í™” ê¸°ë¡ í™•ì¸
            conversation_history = state.get("conversation_history", [])
            logger.info(f"ëŒ€í™” ê¸°ë¡ íƒ€ì…: {type(conversation_history)}, ê¸¸ì´: {len(conversation_history) if isinstance(conversation_history, list) else 'ì•Œ ìˆ˜ ì—†ìŒ'}")
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì˜ì¡´ì„± ë¶„ì„
            # ìˆ˜ì •ëœ ì¡°ê±´: ëŒ€í™” ê¸°ë¡ì´ 2ê°œ ì´ìƒ ìˆëŠ”ì§€ í™•ì¸
            # ìƒìš© ì„œë¹„ìŠ¤ì— ë§ê²Œ type ì†ì„±ì´ ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬
            has_valid_history = (
                conversation_history and 
                isinstance(conversation_history, list) and 
                len(conversation_history) >= 1
            )
            
            if has_valid_history:
                logger.info(f"ëŒ€í™” ê¸°ë¡ ìˆìŒ: {len(conversation_history)}ê°œ ë©”ì‹œì§€")
                context_analysis = await self.analyze_conversation_context(query, conversation_history, stock_name, stock_code, user_id)
                context_analysis_result = context_analysis.model_dump() # dict
                
                # ë¶„ì„ ê²°ê³¼ ìƒíƒœì— ì €ì¥
                state["context_analysis"] = context_analysis_result
                
                # ëŒ€í™” ë§ˆë¬´ë¦¬ ì¸ì‚¬ì¸ì§€ í™•ì¸
                if context_analysis.is_conversation_closing:
                    logger.info(f"ëŒ€í™” ë§ˆë¬´ë¦¬ ì¸ì‚¬ë¡œ ê°ì§€: ìœ í˜•={context_analysis.closing_type}")
                    
                    # ìƒíƒœ ì—…ë°ì´íŠ¸
                    state["agent_results"]["question_analysis"] = context_analysis_result
                    state["summary"] = context_analysis.closing_response
                    state["formatted_response"] = state["summary"]
                    state["answer"] = state["summary"]

                    # ë©”íŠ¸ë¦­ ê¸°ë¡ ë° ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸
                    end_time = datetime.now()
                    duration = (end_time - start_time).total_seconds()
                    
                    state["metrics"] = state.get("metrics", {})
                    state["metrics"]["question_analyzer"] = {
                        "start_time": start_time,
                        "end_time": end_time,
                        "duration": duration,
                        "status": "completed",
                        "error": None,
                        "model_name": self.model_name
                    }
                    
                    state["processing_status"] = state.get("processing_status", {})
                    state["processing_status"]["question_analyzer"] = "completed"
                    
                    logger.info(f"ëŒ€í™” ë§ˆë¬´ë¦¬ ê°ì§€, QuestionAnalyzerAgent ë¹ ë¥¸ ì²˜ë¦¬ ì™„ë£Œ: {duration:.2f}ì´ˆ ì†Œìš”")
                    logger.info(f"ë§ˆë¬´ë¦¬ ìœ í˜•: {context_analysis.closing_type}, ì‘ë‹µ: {context_analysis.closing_response}")
                    return state
                
                if context_analysis.is_different_stock and context_analysis.stock_relation == "ë‹¤ë¥¸ì¢…ëª©":
                    logger.info(f"ì™„ì „íˆ ë‹¤ë¥¸ì¢…ëª© ì§ˆë¬¸")
                    # ìƒíƒœ ì—…ë°ì´íŠ¸
                    state["agent_results"]["question_analysis"] = context_analysis_result
                    state["summary"] = "í˜„ì¬ ì¢…ëª©ê³¼ ê´€ë ¨ì´ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.\në‹¤ë¥¸ ì¢…ëª©ì— ê´€í•œ ì§ˆë¬¸ì€ ìƒˆ ì±„íŒ…ì—ì„œ í•´ì£¼ì„¸ìš”"
                    state["formatted_response"] = state["summary"]
                    state["answer"] = state["summary"]
                    # ë©”íŠ¸ë¦­ ê¸°ë¡ ë° ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸
                    end_time = datetime.now()
                    duration = (end_time - start_time).total_seconds()
                    
                    state["metrics"] = state.get("metrics", {})
                    state["metrics"]["question_analyzer"] = {
                        "start_time": start_time,
                        "end_time": end_time,
                        "duration": duration,
                        "status": "completed",
                        "error": None,
                        "model_name": self.model_name
                    }
                    
                    state["processing_status"] = state.get("processing_status", {})
                    state["processing_status"]["question_analyzer"] = "completed"
                    
                    logger.info(f"ëŒ€í™” ë§ˆë¬´ë¦¬ ê°ì§€, QuestionAnalyzerAgent ë¹ ë¥¸ ì²˜ë¦¬ ì™„ë£Œ: {duration:.2f}ì´ˆ ì†Œìš”")
                    logger.info(f"ë§ˆë¬´ë¦¬ ìœ í˜•: {context_analysis.closing_type}, ì‘ë‹µ: {context_analysis.closing_response}")
                    return state
                
                # í›„ì† ì§ˆë¬¸ì¸ ê²½ìš° ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ê³  ë¦¬í„´
                if context_analysis.requires_context:
                    logger.info("í›„ì† ì§ˆë¬¸ìœ¼ë¡œ ê°ì§€ë˜ì–´ ìƒì„¸ ë¶„ì„ ìƒëµí•˜ê³  ë¹ ë¥´ê²Œ ë¦¬í„´í•©ë‹ˆë‹¤.")

                    
                    state["agent_results"]["question_analysis"] = context_analysis_result
                    
                    # ë©”íŠ¸ë¦­ ê¸°ë¡ ë° ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸
                    end_time = datetime.now()
                    duration = (end_time - start_time).total_seconds()
                    
                    state["metrics"] = state.get("metrics", {})
                    state["metrics"]["question_analyzer"] = {
                        "start_time": start_time,
                        "end_time": end_time,
                        "duration": duration,
                        "status": "completed",
                        "error": None,
                        "model_name": self.model_name
                    }
                    
                    state["processing_status"] = state.get("processing_status", {})
                    state["processing_status"]["question_analyzer"] = "completed"
                    
                    logger.info(f"QuestionAnalyzerAgent ë¹ ë¥¸ ì²˜ë¦¬ ì™„ë£Œ: {duration:.2f}ì´ˆ ì†Œìš”")
                    return state
                
                # í›„ì† ì²˜ë¦¬ì— í•„ìš”í•œ ì •ë³´ ê¸°ë¡
                if context_analysis.requires_context:
                    logger.info(f"ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì°¸ì¡° í•„ìš”: {context_analysis.relation_to_previous}")
                    if context_analysis.referenced_context:
                        logger.info(f"ì°¸ì¡° ì»¨í…ìŠ¤íŠ¸: {context_analysis.referenced_context}")
            else:
                logger.info("ëŒ€í™” ê¸°ë¡ ì—†ìŒ, ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ê±´ë„ˆëœ€")
                state["context_analysis"] = {
                    "requires_context": False,
                    "is_followup_question": False,
                    "relation_to_previous": "ë…ë¦½ì ",
                    "is_conversation_closing": False,
                    "closing_type": None,
                    "closing_response": None,
                    "is_different_stock": False,
                    "previous_stock_name": None,
                    "previous_stock_code": None,
                    "stock_relation": "ì•Œìˆ˜ì—†ìŒ",
                    "reasoning": "ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
                }
            
            logger.info(f"QuestionAnalyzerAgent analyzing query: {query}")
            
            # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™•ì¸
            # 1. ìƒíƒœì—ì„œ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™•ì¸
            custom_prompt_from_state = state.get("custom_prompt_template")
            # 2. ì†ì„±ì—ì„œ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™•ì¸ 
            custom_prompt_from_attr = getattr(self, "prompt_template_test", None)
            
            # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ìš°ì„ ìˆœìœ„: ìƒíƒœ > ì†ì„± > ê¸°ë³¸ê°’
            system_prompt = None
            if custom_prompt_from_state:
                system_prompt = custom_prompt_from_state
                logger.info(f"QuestionAnalyzerAgent using custom prompt from state : {custom_prompt_from_state}")
            elif custom_prompt_from_attr:
                system_prompt = custom_prompt_from_attr
                logger.info(f"QuestionAnalyzerAgent using custom prompt from attribute")
            
            import asyncio
            
            # 1. ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ë° 2. ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰/ëª©ì°¨ ìƒì„±ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
            logger.info("ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„ê³¼ ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰")
            
            # 1. ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ë¹„ë™ê¸° í•¨ìˆ˜
            async def analyze_question_intent():
                # í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
                prompt = format_question_analyzer_prompt(query=query, stock_name=stock_name, stock_code=stock_code, system_prompt=system_prompt)
                
                # LLM í˜¸ì¶œë¡œ ë¶„ì„ ìˆ˜í–‰ - structured output ì‚¬ìš©
                response:QuestionAnalysis = await self.agent_llm.with_structured_output(QuestionAnalysis).ainvoke(
                    prompt, # input=prompt í•˜ë©´ ì•ˆë¨. ê·¸ëƒ¥ prompt ì „ë‹¬
                    user_id=user_id,
                    project_type=ProjectType.STOCKEASY,
                    db=self.db
                )
                response.entities.stock_name = stock_name
                response.entities.stock_code = stock_code

                # ëª¨ë“  ë°ì´í„° ì „ë¶€ on
                response.data_requirements.reports_needed = True
                response.data_requirements.telegram_needed = True
                response.data_requirements.financial_statements_needed = True
                response.data_requirements.industry_data_needed = True
                response.data_requirements.confidential_data_needed = True
                response.data_requirements.revenue_data_needed = True
                # ë¶„ì„ ê²°ê³¼ ë¡œê¹…
                logger.info(f"Analysis result: {response}")

                # ì„œë¸Œê·¸ë£¹ ê°€ì ¸ì˜¤ê¸°
                stock_info_service = StockInfoService()
                subgroup_list = await stock_info_service.get_sector_by_code(stock_code)
                logger.info(f"subgroup_info: {subgroup_list}")

                if subgroup_list and len(subgroup_list) > 0:
                    response.entities.subgroup = subgroup_list
                
                # QuestionAnalysisResult ê°ì²´ ìƒì„± - ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
                question_analysis: QuestionAnalysisResult = {
                    "entities": response.entities.dict(),
                    "classification": response.classification.dict(),
                    "data_requirements": response.data_requirements.dict(),
                    "keywords": response.keywords,
                    "detail_level": response.detail_level
                }
                
                return question_analysis
            
            # 2. ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰ ë° ëª©ì°¨ ìƒì„± ë¹„ë™ê¸° í•¨ìˆ˜
            async def search_issues_and_generate_toc():
                redis_client = self.redis_client
                cache_key_prefix = "recent_issues_summary"
                # user_idë¥¼ ìºì‹œ í‚¤ì—ì„œ ì œì™¸í•˜ì—¬ ì¢…ëª©ë³„ë¡œ ê³µí†µ ìºì‹œ ì‚¬ìš©
                cache_key = f"{cache_key_prefix}:{stock_name}:{stock_code}"

                # 1. ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ
                cached_summary = await redis_client.get_key(cache_key)

                if cached_summary:
                    logger.info(f"ì¢…ëª© [{stock_name}/{stock_code}]ì— ëŒ€í•œ ìºì‹œëœ ìµœê·¼ ì´ìŠˆ ìš”ì•½ ì‚¬ìš©: {cache_key}")
                    recent_issues_summary = cached_summary 
                else:
                    logger.info(f"ì¢…ëª© [{stock_name}/{stock_code}]ì— ëŒ€í•œ ìºì‹œ ì—†ìŒ, ìµœê·¼ ì´ìŠˆ ìš”ì•½ ìƒì„±: {cache_key}")
                    recent_issues_summary = await self.summarize_recent_issues(stock_name, stock_code, user_id)
                    # 2. ìƒì„±ëœ ìš”ì•½ì„ ìºì‹œì— ì €ì¥ (ë§Œë£Œ ì‹œê°„: 1ì¼ = 86400ì´ˆ) -> 2ì¼ë¡œ ë³€ê²½(í¬ë ˆë”§ ë¬¸ì œë•Œë¬¸ì—..)
                    await redis_client.set_key(cache_key, recent_issues_summary, expire=172800)
                    logger.info(f"ì¢…ëª© [{stock_name}/{stock_code}]ì— ìµœê·¼ ì´ìŠˆ ìš”ì•½ ìºì‹œ ì €ì¥ (ë§Œë£Œ: 1ì¼): {cache_key}")

                final_report_toc = await self.generate_dynamic_toc(query, recent_issues_summary, user_id)
                return {
                    "recent_issues_summary": recent_issues_summary,
                    "final_report_toc": final_report_toc.model_dump()
                }
            
            # ë‘ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰
            question_analysis_task = analyze_question_intent()
            issues_and_toc_task = search_issues_and_generate_toc()
            
            # ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘
            question_analysis_result, issues_and_toc_result = await asyncio.gather(
                question_analysis_task,
                issues_and_toc_task
            )
            
            # ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
            state["question_analysis"] = question_analysis_result
            state["agent_results"]["question_analysis"] = question_analysis_result
            state["recent_issues_summary"] = issues_and_toc_result["recent_issues_summary"]
            state["final_report_toc"] = issues_and_toc_result["final_report_toc"]

            # ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # ë©”íŠ¸ë¦­ ê¸°ë¡
            state["metrics"] = state.get("metrics", {})
            state["metrics"]["question_analyzer"] = {
                "start_time": start_time,
                "end_time": end_time,
                "duration": duration,
                "status": "completed",
                "error": None,
                "model_name": self.model_name
            }
            
            # ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸
            state["processing_status"] = state.get("processing_status", {})
            state["processing_status"]["question_analyzer"] = "completed"
            
            logger.info(f"QuestionAnalyzerAgent completed in {duration:.2f} seconds")
            return state
            
        except Exception as e:
            logger.exception(f"Error in QuestionAnalyzerAgent: {str(e)}")
            self._add_error(state, f"ì§ˆë¬¸ ë¶„ì„ê¸° ì—ì´ì „íŠ¸ ì˜¤ë¥˜: {str(e)}")
            return state 

    async def analyze_conversation_context(self, query: str, conversation_history: List[Any], stock_name: str, stock_code: str, user_id: Optional[str] = None) -> ConversationContextAnalysis:
        """
        í˜„ì¬ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì— ì˜ì¡´í•˜ëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            query: í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸
            conversation_history: ì´ì „ ëŒ€í™” ê¸°ë¡ (LangChain ë©”ì‹œì§€ ê°ì²´ ëª©ë¡)
            
        Returns:
            ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼
        """
        logger.info(f"Analyzing conversation context dependency for query: {query}")
        
        if not conversation_history or len(conversation_history) < 2:
            logger.info("ëŒ€í™” ê¸°ë¡ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ, ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ê±´ë„ˆëœ€")
            return ConversationContextAnalysis(
                requires_context=False,
                is_followup_question=False,
                relation_to_previous="ë…ë¦½ì ",
                is_conversation_closing=False,
                closing_type=None,
                closing_response=None,
                is_different_stock=False,
                previous_stock_name=None,
                previous_stock_code=None,
                stock_relation="ì•Œìˆ˜ì—†ìŒ",
                reasoning="ëŒ€í™” ê¸°ë¡ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )
        
        # ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ… (ìµœê·¼ 3ë²ˆì˜ ëŒ€í™”ë§Œ ì‚¬ìš©)
        formatted_history = ""
        recent_history = conversation_history[-6:] if len(conversation_history) >= 6 else conversation_history
        
        for i, msg in enumerate(recent_history):
            role = "ì‚¬ìš©ì" if msg.type == "human" else "AI"
            formatted_history += f"{role}: {msg.content}\n\n"
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸
        system_prompt = """
ë‹¹ì‹ ì€ ëŒ€í™” íë¦„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì¬ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì— ì˜ì¡´í•˜ëŠ”ì§€, ë…ë¦½ì ì¸ ìƒˆ ì§ˆë¬¸ì¸ì§€, ë˜ëŠ” ëŒ€í™” ë§ˆë¬´ë¦¬ë¥¼ ëœ»í•˜ëŠ” ì¸ì‚¬ë§ì¸ì§€ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•˜ì„¸ìš”:
1. ëŒ€ëª…ì‚¬(ì´ê²ƒ, ê·¸ê²ƒ, ì €ê²ƒ ë“±)ë‚˜ ìƒëµëœ ì£¼ì–´ê°€ ìˆëŠ”ì§€
2. ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ íŠ¹ì • ì •ë³´ë¥¼ ì°¸ì¡°í•˜ëŠ”ì§€
3. ì´ì „ ì‘ë‹µì— ëŒ€í•œ í›„ì† ì§ˆë¬¸ì¸ì§€
4. ì´ì „ ì‘ë‹µ ë‚´ìš©ì„ í™•ì¥í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ë ¤ëŠ” ì˜ë„ê°€ ìˆëŠ”ì§€
5. "ê³ ë§ˆì›Œ", "ê°ì‚¬í•©ë‹ˆë‹¤", "ì•Œê² ìŠµë‹ˆë‹¤", "ì •ë³´ê°€ ì—†ë„¤", "ë°”ë³´ì•¼" ë“± ëŒ€í™” ë§ˆë¬´ë¦¬ë¥¼ ëœ»í•˜ëŠ” í‘œí˜„ì¸ì§€
6. í˜„ì¬ ì§ˆë¬¸ì´ ì´ì „ ì§ˆë¬¸ë“¤ì—ì„œ ì–¸ê¸‰ëœ ì¢…ëª©ê³¼ ë‹¤ë¥¸ ì¢…ëª©ì— ê´€í•œ ê²ƒì¸ì§€ íŒë‹¨í•˜ì„¸ìš”

ì˜ˆì‹œ)
 - ê³ ë§ˆì›Œ. ê°ì‚¬í•©ë‹ˆë‹¤ : ëŒ€í™” ë§ˆë¬´ë¦¬
 - ê³ ë§ˆì›Œ, ê·¸ëŸ¼ 24ë…„ ì˜ì—…ì´ìµì€ ì–´ë–»ê²Œ ë˜ëŠ”ê±°ì§€? : í›„ì† ì§ˆë¬¸
 - ì •ë³´ê°€ ì—†ë„¤. ë‹¤ë¥¸ ê²½ìŸì‚¬ë“¤ì€ ì–´ë–»ê²Œ í•˜ëŠ”ì§€ ì°¾ì•„ë´ : í›„ì† ì§ˆë¬¸
 - ë°”ë³´ì•¼ : ëŒ€í™” ë§ˆë¬´ë¦¬

ì¢…ëª© ê´€ê³„ ë¶„ì„ ê°€ì´ë“œ:
- ì¢…ëª©ëª…ì´ë‚˜ ì¢…ëª©ì½”ë“œê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ê²½ìš°, ë§¥ë½ì„ í†µí•´ ë™ì¼ ì¢…ëª©ì— ê´€í•œ ì§ˆë¬¸ì¸ì§€ ì¶”ë¡ í•˜ì„¸ìš”.
- ì§ˆë¬¸ì—ì„œ ìƒˆë¡œìš´ ì¢…ëª©ì´ ì–¸ê¸‰ë˜ì—ˆì§€ë§Œ ì´ì „ ì¢…ëª©ê³¼ì˜ ë¹„êµë¥¼ ìœ„í•œ ê²ƒì´ë¼ë©´, "ì¢…ëª©ë¹„êµ"ë¡œ íŒë‹¨í•˜ì„¸ìš”.
- ì´ì „ ëŒ€í™”ì™€ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ìƒˆë¡œìš´ ì¢…ëª©ì— ëŒ€í•œ ì§ˆë¬¸ì´ë©´ "ë‹¤ë¥¸ì¢…ëª©"ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”.
- ê°™ì€ ì¢…ëª©ì— ëŒ€í•œ í›„ì† ì§ˆë¬¸ì´ë©´ "ë™ì¼ì¢…ëª©"ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”.

ëŒ€í™” ë§ˆë¬´ë¦¬ë¡œ íŒë‹¨ëœ ê²½ìš°, ë§ˆë¬´ë¦¬ ìœ í˜•(ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì )ì— ë”°ë¼ ì ì ˆí•œ ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”:
- ê¸ì •ì  ë§ˆë¬´ë¦¬(ì˜ˆ: "ê°ì‚¬í•©ë‹ˆë‹¤", "ê³ ë§ˆì›Œ"): ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ì—ˆë‹¤ëŠ” ë©”ì‹œì§€ë¡œ ì‘ë‹µ
- ì¤‘ë¦½ì  ë§ˆë¬´ë¦¬(ì˜ˆ: "ì•Œê² ìŠµë‹ˆë‹¤", "ëë‚´ì"): ê°„ê²°í•˜ê³  ì •ì¤‘í•œ ë§ˆë¬´ë¦¬ ë©”ì‹œì§€ë¡œ ì‘ë‹µ
- ë¶€ì •ì  ë§ˆë¬´ë¦¬(ì˜ˆ: "ì •ë³´ê°€ ì—†ë„¤", "ë°”ë³´ì•¼"): ê³µì†í•˜ê²Œ ì‚¬ê³¼í•˜ê³  ë” ë‚˜ì€ ì„œë¹„ìŠ¤ë¥¼ ì•½ì†í•˜ëŠ” ë©”ì‹œì§€ë¡œ ì‘ë‹µ

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:
- requires_context: ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ê°€ í•„ìš”í•œì§€ ì—¬ë¶€(true/false)
- is_followup_question: ì´ì „ ì§ˆë¬¸ì— ëŒ€í•œ í›„ì† ì§ˆë¬¸ì¸ì§€ ì—¬ë¶€(true/false)
- referenced_context: ì°¸ì¡°í•˜ëŠ” íŠ¹ì • ëŒ€í™” ë‚´ìš©(ìˆëŠ” ê²½ìš°)
- relation_to_previous: ì´ì „ ëŒ€í™”ì™€ì˜ ê´€ê³„("ë…ë¦½ì ", "ì§ì ‘ì°¸ì¡°", "ê°„ì ‘ì°¸ì¡°", "í™•ì¥", "ìˆ˜ì •" ì¤‘ í•˜ë‚˜)
- is_conversation_closing: ëŒ€í™” ë§ˆë¬´ë¦¬ë¥¼ ëœ»í•˜ëŠ” ì¸ì‚¬ë§ì¸ì§€ ì—¬ë¶€(true/false)
- closing_type: ë§ˆë¬´ë¦¬ ì¸ì‚¬ì˜ ìœ í˜•("ê¸ì •ì ", "ì¤‘ë¦½ì ", "ë¶€ì •ì " ì¤‘ í•˜ë‚˜, is_conversation_closingì´ trueì¸ ê²½ìš°ì—ë§Œ ê°’ ì œê³µ)
- closing_response: ë§ˆë¬´ë¦¬ ì¸ì‚¬ì— ëŒ€í•œ ì‘ë‹µ ë©”ì‹œì§€(is_conversation_closingì´ trueì¸ ê²½ìš°ì—ë§Œ ê°’ ì œê³µ)
- is_different_stock: ì´ì „ ì§ˆë¬¸ê³¼ ë‹¤ë¥¸ ì¢…ëª©ì— ê´€í•œ ì§ˆë¬¸ì¸ì§€ ì—¬ë¶€(true/false)
- previous_stock_name: ì´ì „ ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ì¢…ëª©ëª…(ìˆëŠ” ê²½ìš°)
- previous_stock_code: ì´ì „ ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ì¢…ëª©ì½”ë“œ(ìˆëŠ” ê²½ìš°)
- stock_relation: ì´ì „ ì¢…ëª©ê³¼ì˜ ê´€ê³„("ë™ì¼ì¢…ëª©", "ì¢…ëª©ë¹„êµ", "ë‹¤ë¥¸ì¢…ëª©", "ì•Œìˆ˜ì—†ìŒ" ì¤‘ í•˜ë‚˜)
- reasoning: íŒë‹¨ ì´ìœ  ì„¤ëª…(3-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ)
"""
        
        user_prompt = f"""
ëŒ€í™” ê¸°ë¡:
{formatted_history}

í˜„ì¬ ì§ˆë¬¸:
{query}

í˜„ì¬ ì¢…ëª© ì •ë³´: [ì¢…ëª©ëª…: {stock_name}, ì¢…ëª©ì½”ë“œ: {stock_code}]

ìœ„ ëŒ€í™”ì—ì„œ í˜„ì¬ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì— ì˜ì¡´í•˜ëŠ”ì§€, ëŒ€í™” ë§ˆë¬´ë¦¬ í‘œí˜„ì¸ì§€, ì¢…ëª© ê´€ê³„ëŠ” ì–´ë–¤ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""

        try:
            prompt = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            formatted_prompt = f"{system_prompt}\n\n{user_prompt}"
            # LLM í˜¸ì¶œë¡œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
            response = await self.agent_llm_lite.with_structured_output(ConversationContextAnalysis).ainvoke(
                formatted_prompt,
                project_type=ProjectType.STOCKEASY,
                user_id=user_id,
                db=self.db
            )
            
            logger.info(f"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼: {response}")
            return response
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return ConversationContextAnalysis(
                requires_context=False,
                is_followup_question=False,
                relation_to_previous="ë…ë¦½ì ",
                is_conversation_closing=False,
                closing_type=None,
                closing_response=None,
                is_different_stock=False,
                previous_stock_name=None,
                previous_stock_code=None,
                stock_relation="ì•Œìˆ˜ì—†ìŒ",
                reasoning=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )
    
    def _add_error(self, state: Dict[str, Any], error_message: str) -> None:
        """
        ìƒíƒœ ê°ì²´ì— ì˜¤ë¥˜ ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        
        Args:
            state: ìƒíƒœ ê°ì²´
            error_message: ì˜¤ë¥˜ ë©”ì‹œì§€
        """
        state["errors"] = state.get("errors", [])
        state["errors"].append({
            "agent": "question_analyzer",
            "error": error_message,
            "type": "processing_error",
            "timestamp": datetime.now(),
            "context": {"query": state.get("query", "")}
        })
        
        # ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸
        state["processing_status"] = state.get("processing_status", {})
        state["processing_status"]["question_analyzer"] = "failed" 
    
        
    # ë™ì  ëª©ì°¨ ìƒì„± í•¨ìˆ˜ ì¶”ê°€
    async def generate_dynamic_toc(self, query: str, recent_issues_summary: str, user_id: str) -> DynamicTocOutput:
        """
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ìµœê·¼ ì´ìŠˆ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ë™ì ì¸ ëª©ì°¨ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            query (str): ì‚¬ìš©ìì˜ ì´ˆê¸° ì§ˆë¬¸
            recent_issues_summary (str): ìµœê·¼ ì´ìŠˆ ìš”ì•½

        Returns:
            DynamicTocOutput: ìƒì„±ëœ ëª©ì°¨ êµ¬ì¡°
        """
        print("\nğŸ“‹ ë™ì  ëª©ì°¨ ìƒì„± ì¤‘...")
        
        #llm_lite = get_llm_for_agent("gemini-lite")

        prompt_template = ChatPromptTemplate.from_template(PROMPT_DYNAMIC_TOC).partial(
            query=query,
            recent_issues_summary=recent_issues_summary,
            today_date=datetime.now().strftime("%Y-%m-%d")
        )
        formatted_prompt = prompt_template.format_prompt()
        
        response:AIMessage = await self.agent_llm.ainvoke_with_fallback(
                formatted_prompt,
                project_type=ProjectType.STOCKEASY,
                user_id=user_id,
                db=self.db
            )
        
        # # êµ¬ì¡°í™”ëœ ì¶œë ¥ ëŒ€ì‹  ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µìœ¼ë¡œ ë°›ìŒ
        # chain = prompt_template | llm_lite | StrOutputParser()
        
        # # LLMì— ìš”ì²­ ë³´ë‚´ê¸°
        # response_text = await chain.ainvoke({
        #     "query": query, 
        #     "recent_issues_summary": recent_issues_summary
        # })
        

        response_text = response.content
        print("\nğŸ“„ LLM ì›ë³¸ ì‘ë‹µ:")
        print(response_text[:200]) # ì‘ë‹µ ì¼ë¶€ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        
        # JSON ë¬¸ìì—´ì„ íŒŒì‹±
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ (LLMì´ JSON ì™¸ì— ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŒ)
            import re
            import json
            
            # JSON íŒ¨í„´ ì°¾ê¸° (ì¤‘ê´„í˜¸ë¡œ ê°ì‹¸ì§„ ë¶€ë¶„)
            json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}))*\}'
            json_match = re.search(json_pattern, response_text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(0)
                # JSON ë¬¸ìì—´ íŒŒì‹±
                toc_data = json.loads(json_str)
                print("\nâœ… JSON íŒŒì‹± ì„±ê³µ")
            else:
                # JSON íŒ¨í„´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
                print("\nâš ï¸ JSON íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ ëª©ì°¨ êµ¬ì¡° ì‚¬ìš©")
                toc_data = {
                    "title": f"íˆ¬ì ë¦¬ì„œì¹˜ ë³´ê³ ì„œ: {query}",
                    "sections": [
                        {
                            "section_id": "section_1",
                            "title": "í•µì‹¬ ìš”ì•½ (Executive Summary)",
                            "description": "ì£¼ìš” ë°œê²¬ê³¼ ê²°ë¡ ì„ ìš”ì•½",
                            "subsections": []
                        },
                        {
                            "section_id": "section_2", 
                            "title": "ê¸°ì—… ê°œìš” ë° ì‚¬ì—… ëª¨ë¸",
                            "description": "ê¸°ì—…ì˜ ê¸°ë³¸ ì •ë³´ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¶„ì„",
                            "subsections": []
                        },
                        {
                            "section_id": "section_3",
                            "title": "ì‚°ì—…/ì‹œì¥ ë™í–¥ ë¶„ì„",
                            "description": "ê¸°ì—…ì´ ì†í•œ ì‚°ì—…ì˜ í˜„í™©ê³¼ ì „ë§",
                            "subsections": []
                        }
                    ],
                    "rationale": "ê¸°ë³¸ ëª©ì°¨ êµ¬ì¡° ì‚¬ìš©"
                }
        except Exception as e:
            print(f"\nâš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}, ê¸°ë³¸ ëª©ì°¨ êµ¬ì¡° ì‚¬ìš©")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ëª©ì°¨ êµ¬ì¡° ì‚¬ìš©
            toc_data = {
                "title": f"íˆ¬ì ë¦¬ì„œì¹˜ ë³´ê³ ì„œ: {query}",
                "sections": [
                    {
                        "section_id": "section_1",
                        "title": "í•µì‹¬ ìš”ì•½ (Executive Summary)",
                        "description": "ì£¼ìš” ë°œê²¬ê³¼ ê²°ë¡ ì„ ìš”ì•½",
                        "subsections": []
                    },
                    {
                        "section_id": "section_2", 
                        "title": "ê¸°ì—… ê°œìš” ë° ì‚¬ì—… ëª¨ë¸",
                        "description": "ê¸°ì—…ì˜ ê¸°ë³¸ ì •ë³´ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¶„ì„",
                        "subsections": []
                    },
                    {
                        "section_id": "section_3",
                        "title": "ì‚°ì—…/ì‹œì¥ ë™í–¥ ë¶„ì„",
                        "description": "ê¸°ì—…ì´ ì†í•œ ì‚°ì—…ì˜ í˜„í™©ê³¼ ì „ë§",
                        "subsections": []
                    }
                ],
            }
        
        # íŒŒì‹±ëœ ë°ì´í„°ë¡œ DynamicTocOutput ê°ì²´ ìƒì„±
        result = DynamicTocOutput(
            title=toc_data.get("title", f"íˆ¬ì ë¦¬ì„œì¹˜ ë³´ê³ ì„œ: {query}"),
            sections=toc_data.get("sections", []),
            rationale=toc_data.get("rationale", "")
        )
        
        print(f"\nâœ… ë™ì  ëª©ì°¨ ìƒì„± ì™„ë£Œ. ì´ {len(result.sections)}ê°œ ì„¹ì…˜ í¬í•¨")
        print(f"ğŸ“š ë³´ê³ ì„œ ì œëª©: {result.title}")
        
        # ì„¹ì…˜ ì •ë³´ ìƒì„¸ ì¶œë ¥
        print(f"ğŸ“‘ ëª©ì°¨ êµ¬ì¡°:")
        for i, section in enumerate(result.sections, 1):
            # ì„¹ì…˜ ì œëª©ê³¼ ì„¤ëª… ì¶œë ¥
            section_title = section.get('title', 'ì œëª© ì—†ìŒ')
            section_desc = section.get('description', '')
            print(f"  {section_title}")
            if section_desc:
                print(f"     - {section_desc}")
                
            # í•˜ìœ„ ì„¹ì…˜ì´ ìˆìœ¼ë©´ ì¶œë ¥
            if 'subsections' in section and section['subsections']:
                for j, subsection in enumerate(section['subsections'], 1):
                    subsection_title = subsection.get('title', 'ì œëª© ì—†ìŒ')
                    print(f"     {subsection_title}")
        
        return result
    
    async def summarize_recent_issues(self, stock_name: str, stock_code: str, user_id: str) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ ìµœê·¼ ì´ìŠˆ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""

        search_results = await self.search_recent_issues(stock_name, stock_code) # ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰

        print(f"\nğŸ“ {stock_name}ì˜ ìµœê·¼ ì´ìŠˆ ìš”ì•½ ì¤‘...")
        prompt = f"""
    ë‹¤ìŒì€ '{stock_name}'ì— ëŒ€í•œ ìµœê·¼ ì£¼ìš” ë‰´ìŠ¤ ë° ì´ìŠˆ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ìš” ë‰´ìŠ¤ ì œëª©, í•µì‹¬ ì´ìŠˆ, ë°˜ë³µì ìœ¼ë¡œ ì–¸ê¸‰ë˜ëŠ” í‚¤ì›Œë“œë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. ìš”ì•½ì€ç®‡æ¡æ›¸ã(ë¶ˆë¦¿ í¬ì¸íŠ¸) í˜•ì‹ì„ ì‚¬ìš©í•˜ê³ , ê°€ì¥ ì¤‘ìš”í•œ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•´ì£¼ì„¸ìš”.

    ê²€ìƒ‰ ê²°ê³¼:
    {search_results}

    ìµœê·¼ ì£¼ìš” ë‰´ìŠ¤ ë° ì´ìŠˆ ê²€ìƒ‰ ê²°ê³¼ í‚¤ì›Œë“œ ìš”ì•½:
    """
        try:
            response = await self.agent_llm_lite.ainvoke_with_fallback(
                prompt,
                project_type=ProjectType.STOCKEASY,
                user_id=user_id,
                db=self.db
            )

            summary = response.content
            print(f"  ğŸ“ {stock_name} ìµœê·¼ ì´ìŠˆ ìš”ì•½ ì™„ë£Œ.")
            #print(f"=== ìš”ì•½ ë‚´ìš© ===\\n{summary}\\n===========") # ë””ë²„ê¹…ìš©
            return summary
        except Exception as e:
            print(f"  âš ï¸ {stock_name} ìµœê·¼ ì´ìŠˆ ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return f"{stock_name} ìµœê·¼ ì´ìŠˆ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    # --- END: ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰ ë° ìš”ì•½ í•¨ìˆ˜ ---

    async def search_recent_issues(self, stock_name: str, stock_code: str) -> str:
        """Tavily APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì¢…ëª©ì˜ ìµœê·¼ 6ê°œì›”ê°„ ì£¼ìš” ë‰´ìŠ¤ ë° ì´ìŠˆë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        print(f"\nğŸ” {stock_name}ì˜ ìµœê·¼ ì£¼ìš” ì´ìŠˆ ê²€ìƒ‰ ì¤‘...")
        query = f"{stock_name} ìµœê·¼ ì£¼ìš” ë‰´ìŠ¤ ë° í•µì‹¬ ì´ìŠˆ"
        try:
            # search_with_tavily í•¨ìˆ˜ë¥¼ ì¬ì‚¬ìš©í•˜ê±°ë‚˜ ì§ì ‘ Tavily í˜¸ì¶œ ë¡œì§ êµ¬í˜„
            search_results = await self.search_with_tavily(query) 
            print(f"  ğŸ“Š {stock_name} ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰ ì™„ë£Œ.\n[{search_results[:200]}]")
            
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
            await self._save_recent_issues_to_json(stock_name, stock_code, query, search_results)
            
            return search_results
        except Exception as e:
            print(f"  âš ï¸ {stock_name} ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return f"{stock_name} ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            
    async def _save_recent_issues_to_json(self, stock_name: str, stock_code: str, 
                                         query: str, search_results: Any) -> None:
        """
        ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¼ìë³„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.
        
        Args:
            stock_name: ì¢…ëª© ì´ë¦„
            stock_code: ì¢…ëª© ì½”ë“œ
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            search_results: Tavily API ê²€ìƒ‰ ê²°ê³¼
            
        Returns:
            None
        """
        try:
            # íŒŒì¼ I/O ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì •ì˜
            def write_to_json() -> str:
                # JSON íŒŒì¼ ê²½ë¡œ ì„¤ì •
                json_dir = os.path.join('stockeasy', 'local_cache', 'web_search')
                os.makedirs(json_dir, exist_ok=True)
                
                date_str = datetime.now().strftime('%Y%m%d')
                json_path = os.path.join(json_dir, f'recent_issues_{date_str}.json')
                
                # í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„
                current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                # ì €ì¥í•  ë°ì´í„° êµ¬ì„±
                entry = {
                    "timestamp": current_datetime,
                    "stock_code": stock_code,
                    "stock_name": stock_name,
                    "query": query,
                    "search_results": search_results
                }
                
                # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                data = []
                if os.path.exists(json_path) and os.path.getsize(json_path) > 0:
                    try:
                        with open(json_path, 'r', encoding='utf-8-sig') as json_file:
                            data = json.load(json_file)
                    except json.JSONDecodeError:
                        # íŒŒì¼ì´ ì†ìƒëœ ê²½ìš° ìƒˆë¡œ ì‹œì‘
                        data = []
                
                # ë°ì´í„° ì¶”ê°€
                data.append(entry)
                
                # íŒŒì¼ì— ì €ì¥
                with open(json_path, 'w', encoding='utf-8-sig') as json_file:
                    json.dump(data, json_file, ensure_ascii=False, indent=2)
                
                return json_path
            
            # íŒŒì¼ I/O ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
            json_path = await asyncio.to_thread(write_to_json)
            
            print(f"  ğŸ’¾ {stock_name} ìµœê·¼ ì´ìŠˆ ê²€ìƒ‰ê²°ê³¼ê°€ JSON íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {json_path}")
            
        except Exception as e:
            print(f"  âš ï¸ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    async def search_with_tavily(self, query: str) -> str:
        """Tavily APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            # search_results = await self.tavily_search.ainvoke({"query": query, 
            #                                                    "search_depth":"basic",# "advanced",
            #                                                 "max_results": 10, 
            #                                                 "topic": "general",
            #                                                 #"topic":"finance",
            #                                                 "time_range" : "6m",
            #                                                 "chunks_per_source": 3,
            #                                                 "include_raw_content": True,
            #                                                 "include_answer":True
            #                                                 })
            # search_results = await self.tavily_search.ainvoke({"query": query, 
            #                                     "search_depth": "advanced", # "basic",
            #                                     #"search_depth": "basic", # "basic",
            #                                     "max_results": 14, 
            #                                     "topic": "general",
            #                                     #"topic":"finance",
            #                                     "time_range" : "year",
            #                                     })
            search_results = await self.tavily_service.search_async(query=query, 
                                                search_depth="advanced", # "basic",
                                                #"search_depth": "basic", # "basic",
                                                max_results=14, 
                                                topic="general",
                                                #"topic":"finance",
                                                time_range="year",
                                                )
            
            print(f"ê²€ìƒ‰ê²°ê³¼ : {search_results}")
            print(f"ê²€ìƒ‰ê²°ê³¼ ì‹œê°„ : {search_results.get('response_time', '0')}")
            print(f"ê²€ìƒ‰ê²°ê³¼ ì‘ë‹µ : {search_results.get('answer', 'None')}")
            formatted_results = "ê²€ìƒ‰ ê²°ê³¼:\n\n"
            for i, result_item in enumerate(search_results.get('results', []), 1):
                # result_itemì´ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸ í›„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
                if isinstance(result_item, dict):
                    formatted_results += f"{i}. ì œëª©: {result_item.get('title', 'ì œëª© ì—†ìŒ')}\n"
                    formatted_results += f"   URL: {result_item.get('url', 'ë§í¬ ì—†ìŒ')}\n"
                    formatted_results += f"   ë‚´ìš©: {result_item.get('content', 'ë‚´ìš© ì—†ìŒ')}\n\n"
                else:
                    # result_itemì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ë¡œê·¸ë¥¼ ë‚¨ê¸°ê±°ë‚˜ ë‹¤ë¥¸ ì²˜ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    logger.warning(f"ê²€ìƒ‰ ê²°ê³¼ í•­ëª©ì´ ì˜ˆìƒëœ ë”•ì…”ë„ˆë¦¬ íƒ€ì…ì´ ì•„ë‹™ë‹ˆë‹¤: {result_item}")
                    formatted_results += f"{i}. ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ê²°ê³¼ í•­ëª©ì…ë‹ˆë‹¤.\n\n"
            return formatted_results
        except Exception as e:
            print(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            print(search_results)
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        
